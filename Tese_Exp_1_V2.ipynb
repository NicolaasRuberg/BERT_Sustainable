{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Tese_Exp_1_V2.ipynb","provenance":[{"file_id":"1MUZOkqiK6y1SAsKpbPOLZuJZvI5bGL2x","timestamp":1626249129862}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"6ae129deb3ce4520a1af7795d8a879e7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ded7ad24a3334929a8361406e0e42403","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7ede662df1a64dfb910eed135d87955a","IPY_MODEL_c2db5e3e4c0a4d338360eb0171ba1109","IPY_MODEL_81b23ad5ca2143f79ee2b6938195e703"]}},"ded7ad24a3334929a8361406e0e42403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ede662df1a64dfb910eed135d87955a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a869f27dd8934d5d8ed402067efb1862","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9ce941df24464f7ba9541f129e3f9df7"}},"c2db5e3e4c0a4d338360eb0171ba1109":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3d6175c4a4d64ef394c37ddeb2724440","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":871891,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":871891,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d3592a3189a640d987368eb248fa8fd5"}},"81b23ad5ca2143f79ee2b6938195e703":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6b15f5b3098943849a2d8f517e143748","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 872k/872k [00:00&lt;00:00, 1.56MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4daa542ada3499aa75b009ff853d4b1"}},"a869f27dd8934d5d8ed402067efb1862":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9ce941df24464f7ba9541f129e3f9df7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d6175c4a4d64ef394c37ddeb2724440":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d3592a3189a640d987368eb248fa8fd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6b15f5b3098943849a2d8f517e143748":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e4daa542ada3499aa75b009ff853d4b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b47bf091e3e546c98e2f843b07f40afc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c6b237d5a6e94e869dfad227d76b699f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_28dff05186ab461fa263e924cdaa39fc","IPY_MODEL_2c0b3920c1fd477ca96f9a0692c335fb","IPY_MODEL_fda21886846544909346ebfcffdc2410"]}},"c6b237d5a6e94e869dfad227d76b699f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28dff05186ab461fa263e924cdaa39fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_03eaa07b19f44f57bbbbfea5aa715fb5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_82c392f0cc634063a389ce97fca6a2aa"}},"2c0b3920c1fd477ca96f9a0692c335fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2ed24fef594d4d54a8f2a0c554bb73a0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_656e6797f5084916ac7bbab06de1099b"}},"fda21886846544909346ebfcffdc2410":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6a247a17bbc44b43b1c0cc5f92ed0a01","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 976B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_346f2a9cab8144f8b5d03ced9ba3d821"}},"03eaa07b19f44f57bbbbfea5aa715fb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"82c392f0cc634063a389ce97fca6a2aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ed24fef594d4d54a8f2a0c554bb73a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"656e6797f5084916ac7bbab06de1099b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a247a17bbc44b43b1c0cc5f92ed0a01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"346f2a9cab8144f8b5d03ced9ba3d821":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"009fe2137f44437c95de6179aa08ad2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b64dbce3a8be4087ad791677de283aad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_154c02f19c594e97bd8ecb1a66058056","IPY_MODEL_46359f1cb8e3458f895caae2ef0550ef","IPY_MODEL_ae91962003d84ddaab495ea764832d75"]}},"b64dbce3a8be4087ad791677de283aad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"154c02f19c594e97bd8ecb1a66058056":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0933dd9850484954833f0fce901f3f10","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41c8933cd5ac4d25951cb832c2a967ef"}},"46359f1cb8e3458f895caae2ef0550ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3072237a87d74386968f95adf5c33012","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1715180,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1715180,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6302fdd0e5744bbeb4a3ae32fb092b9c"}},"ae91962003d84ddaab495ea764832d75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_66cfba832c944d909e750fa3f6300fa0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.72M/1.72M [00:00&lt;00:00, 1.82MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6cb86bdb4c614eef994ef8c727ba9ddf"}},"0933dd9850484954833f0fce901f3f10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"41c8933cd5ac4d25951cb832c2a967ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3072237a87d74386968f95adf5c33012":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6302fdd0e5744bbeb4a3ae32fb092b9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66cfba832c944d909e750fa3f6300fa0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6cb86bdb4c614eef994ef8c727ba9ddf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b713934421ac4baa830195833be1f9f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9f8d3b15ecc343b88c0fa373eacea8cb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b92eeb31b68342c086f7c3e604a6b162","IPY_MODEL_b85b12b16fb94924af3e3f4fcb590e9e","IPY_MODEL_42297ee68e0b4ce182f64269e9fc552a"]}},"9f8d3b15ecc343b88c0fa373eacea8cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b92eeb31b68342c086f7c3e604a6b162":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_da4dcdfcfa644ce083c3b0500f1e6b05","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d1e6689360b4ae5b89b9d2b03b93e7c"}},"b85b12b16fb94924af3e3f4fcb590e9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2d954dd61a7c46f7834fdafee64f78dc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a755f17dcb3948c68cf898b908b9b7e3"}},"42297ee68e0b4ce182f64269e9fc552a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f6a7c9338c7d4880a9f9ca433bb59713","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 22.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e0f914fb9b040939b7a0f45948ad528"}},"da4dcdfcfa644ce083c3b0500f1e6b05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3d1e6689360b4ae5b89b9d2b03b93e7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d954dd61a7c46f7834fdafee64f78dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a755f17dcb3948c68cf898b908b9b7e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f6a7c9338c7d4880a9f9ca433bb59713":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e0f914fb9b040939b7a0f45948ad528":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7deb16dbc6ca49e59b8f7e917d45edcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b329b6a57894034b552c385959b0636","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_300f17232f9c43fb9da6384a129618e4","IPY_MODEL_06844bf750a346e8a77913109e000caf","IPY_MODEL_7c21cd2609374d0d900cde723434ced5"]}},"1b329b6a57894034b552c385959b0636":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"300f17232f9c43fb9da6384a129618e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e7ea03af4534312894e9a1ceca1310a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_011455c31b234b26a3c5c9983c50e218"}},"06844bf750a346e8a77913109e000caf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f8765c11ff6046a0adaa1aa6a71bb7c6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":999358484,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":999358484,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95a2a1f8a05c4db4810e79fa3b186f0e"}},"7c21cd2609374d0d900cde723434ced5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c42360544bb94caa9f26ace5276d8826","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 999M/999M [00:17&lt;00:00, 57.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1735dcce47543d398b5cdd45995ced6"}},"2e7ea03af4534312894e9a1ceca1310a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"011455c31b234b26a3c5c9983c50e218":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8765c11ff6046a0adaa1aa6a71bb7c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"95a2a1f8a05c4db4810e79fa3b186f0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c42360544bb94caa9f26ace5276d8826":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a1735dcce47543d398b5cdd45995ced6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"p5Vc-7MzQB28"},"source":["# 1st Experiment classifying GRIs into Concepts: 200,300,400\n","\n","> This script is used to train a multiclass classifier using Bert and some other flavors, also we provide the evaluation of each strategy. For better performance we use a TPU backend.\n","\n","\n","> To run on Google Drive, the input data (training and validation) is expected in the folder named SQUAD MATERIAL.\n","\n","OBS.: Need to treat words like im- pact "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAwNcI_i2JNy","executionInfo":{"status":"ok","timestamp":1632472111967,"user_tz":180,"elapsed":282,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"37ed94d5-f817-4762-c9a4-de8094c6baf4"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 37.8 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jxuqf1a7EUmD","executionInfo":{"status":"ok","timestamp":1632472137332,"user_tz":180,"elapsed":17947,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"58b900b4-b64f-4af4-a616-c08f144ebda6"},"source":["!pip install tokenizers\n","!pip install transformers\n","\n","import json\n","import pandas as pd\n","import string\n","import re\n","import gc\n","import os\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import tensorflow.keras.layers as layers\n","\n","!pip install sentencepiece\n","from transformers import BertTokenizer, TFBertModel\n","from transformers import DistilBertTokenizer, TFDistilBertModel\n","from transformers import RobertaTokenizer, TFRobertaModel\n","from transformers import ElectraTokenizer, TFElectraModel\n","from transformers import FunnelTokenizer, TFFunnelForTokenClassification\n","from transformers import AlbertTokenizer, TFAlbertModel"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tokenizers\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 5.3 MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.10.3\n","Collecting transformers\n","  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 5.3 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 71.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Collecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 74.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.45 transformers-4.10.3\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9pZ6AswbNFsM","executionInfo":{"status":"ok","timestamp":1632472163556,"user_tz":180,"elapsed":25422,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"bdb5cdb7-3d1c-45a3-c1f0-3ee2d5f45a2d"},"source":["# Accessing local drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/NLP_tese/Exp1"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/NLP_tese/Exp1\n"]}]},{"cell_type":"code","metadata":{"id":"c388aDw9OTT4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632472166013,"user_tz":180,"elapsed":1718,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"274673d4-074d-4763-c5c5-389210808d8d"},"source":["import nltk\n","from nltk.corpus import stopwords\n","from functools import reduce\n","\n","REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n","GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n","try:\n","    STOPWORDS = set(stopwords.words('english'))\n","except LookupError:\n","    nltk.download('stopwords')\n","    STOPWORDS = set(stopwords.words('english'))\n","def lower(text):\n","    return text.lower()\n","def replace_special_characters(text):\n","    return REPLACE_BY_SPACE_RE.sub(' ', text)\n","def filter_out_uncommon_symbols(text):\n","    return GOOD_SYMBOLS_RE.sub('', text)\n","def remove_stopwords(text):\n","    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n","def strip_text(text):\n","    return text.strip()\n","def remove_GRI(text):\n","    regex = re.compile(r'GRI|gri', re.UNICODE)\n","    return re.sub(regex, '', text)\n","def remove_articles(text):\n","    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n","    return re.sub(regex, ' ', text)\n","def remove_numbers(text):\n","    regex = re.compile(r'[0-9]', re.UNICODE)\n","    return re.sub(regex, ' ', text)\n"," \n","PREPROCESSING_PIPELINE = [\n","                          remove_articles,\n","                          remove_GRI,\n","                          lower,\n","                          replace_special_characters,\n","                          filter_out_uncommon_symbols,\n","                          remove_stopwords,\n","                          strip_text,\n","                          remove_numbers# Remove numbers\n","                          ]\n","# Anchor method\n","def text_prepare(text, filter_methods=None):\n","    \"\"\"\n","    Applies a list of pre-processing functions in sequence (reduce).\n","    Note that the order is important here!\n","    \"\"\"\n","\n","    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n","\n","    return reduce(lambda txt, f: f(txt), filter_methods, text)\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"SIO1YVQKGMFB","executionInfo":{"status":"ok","timestamp":1632472166015,"user_tz":180,"elapsed":13,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}}},"source":["## Implementing our new creat_dataframe function \n","def aggregate_cat(txt):\n","  txt_100 = re.sub('^1[0-9][0-9]\\-[0-9]+', '100', txt.strip())\n","  txt_200 = re.sub('^2[0-9][0-9]\\-[0-9]+', '200', txt_100)\n","  txt_300 = re.sub('^3[0-9][0-9]\\-[0-9]+', '300', txt_200)\n","  txt_400 = re.sub('^4[0-9][0-9]\\-[0-9]+', '400', txt_300)\n","  return (txt_400)\n","\n","def create_dataframe(ds, tokenizer, maxlen=512, stride=30, split=0.9, use_token_type_ids=True):\n","  samples = []\n","  # We have our ds with the format of <Filename,GRI,Text>\n","  #let's start aggregating our 200,300 and 400 categories\n","  print(ds.dtypes)\n","  ds['GRI'] = ds['GRI'].apply(lambda txt: aggregate_cat(txt))\n","  ds['GRI'] = pd.to_numeric(ds['GRI']).astype('int32') \n","  # Let's remove the 100 category\n","  ds.drop(ds[ds['GRI'] == 100].index, inplace=True)\n","  ds = ds.reset_index(drop=True)\n","  ds['GRI'] = ds['GRI'].astype('int32') \n","  # We clean our text data\n","  ds['Text'] = ds['Text'].apply(lambda txt: text_prepare(txt))\n","  ###\n","  for index, row in ds.iterrows():\n","    tmp_a = row['Text']\n","    tmp_gri = row['GRI']\n","    tmp_filename = row['Filename']\n","    tmp_tokens = tokenizer(tmp_a)\n","    tok_len = len(tmp_tokens[\"input_ids\"])\n","    idx = tmp_tokens[\"input_ids\"].index(tokenizer.sep_token_id)\n","    # Split between train and validation according to the data field in the original dataframe.\n","    tmp_split = \"train\" if index < len(ds['Text']) * split else \"validation\"\n","    # If the total length exceeds the window length, the context is split with a partial overlap governed by stride.\n","    if tok_len > maxlen:\n","      print(\"##Warning: token length larger than the maximum ({}). Splitting answer into partially overlapped chunks...\".format(tok_len))\n","      print(tmp_a)\n","    else:\n","      if use_token_type_ids:\n","        samples.append({\"filename\": tmp_filename, \"text\": tmp_a, \"gri\": tmp_gri, \"input_ids\": tmp_tokens[\"input_ids\"], \"token_type_ids\": tmp_tokens[\"token_type_ids\"], \"attention_mask\": tmp_tokens[\"attention_mask\"], \"split\": tmp_split})\n","      else:\n","        samples.append({\"filename\": tmp_filename, \"text\": tmp_a, \"gri\": tmp_gri, \"input_ids\": tmp_tokens[\"input_ids\"], \"attention_mask\": tmp_tokens[\"attention_mask\"], \"split\": tmp_split})\n","\n","  return pd.DataFrame(samples)\n","\n","# Returns tensors for the model, starting from the provided dataframe (which contains prewindowed entries).\n","def generate_samples(df, max_len, use_token_type_ids=True):\n","  input_ids = np.zeros((len(df), max_len), dtype=np.int32)\n","  attention_mask = np.zeros((len(df), max_len), dtype=np.bool)\n","  class_ESG = np.zeros((len(df),3), dtype=np.bool)\n","\n","  print(df.dtypes)\n","  if use_token_type_ids:\n","    token_type_ids = np.zeros((len(df), max_len), dtype=np.uint8)\n","\n","  for i in range(len(df)):\n","    tmp_length = len(df[\"input_ids\"].loc[i])\n","    input_ids[i,:tmp_length] = df[\"input_ids\"].loc[i]\n","    attention_mask[i,:tmp_length] = df[\"attention_mask\"].loc[i]\n","    if use_token_type_ids:\n","      token_type_ids[i,:tmp_length] = df[\"token_type_ids\"].loc[i]\n","    # we want class_ESG with vector(3) with [1,0,0] if 200, [0,1,0]\n","    if df['gri'].loc[i] == 200:\n","      class_ESG[i,0] = 1\n","    elif df['gri'].loc[i] == 300:\n","      class_ESG[i,1] = 1\n","    else :\n","      class_ESG[i,2] = 1\n","  # End for\n","\n","  if use_token_type_ids:\n","    return [input_ids, token_type_ids, attention_mask], [class_ESG]\n","  else:\n","    return [input_ids, attention_mask], [class_ESG]\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OFNNxrmxeg1W"},"source":["### Preprocessing and windowing"]},{"cell_type":"markdown","metadata":{"id":"UzJ298hdel31"},"source":["### Model"]},{"cell_type":"code","metadata":{"id":"lZagq1mCDWJ-","executionInfo":{"status":"ok","timestamp":1632472166016,"user_tz":180,"elapsed":12,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}}},"source":["# Modular model topology. Takes an encoder layer and connects it to text head. \n","# https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n","\n","def model_topology(encoder, max_len=512, use_pooler=True, use_token_type_ids=True):\n","  input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n","  attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n","\n","  if use_token_type_ids:\n","    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    transformer = encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n","  else:\n","    transformer = encoder(input_ids, attention_mask=attention_mask)\n","  # we predict 3 classes (200,300,400), so units=3\n","  if use_pooler:\n","    class_ESG = layers.Dense(units=3, activation=\"sigmoid\")(transformer[\"pooler_output\"])\n","  else:\n","    transformer = layers.Flatten()(transformer[\"last_hidden_state\"])\n","    class_ESG = layers.Dense(units=3, activation=\"sigmoid\")(transformer)\n","\n","  optimizer = keras.optimizers.Adam(learning_rate=5e-5) \n","  # From https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a\n","  # We have this suggestion for the optimizer\n","  # optimizer = Adam( learning_rate=5e-05, epsilon=1e-08, decay=0.01, clipnorm=1.0)\n","\n","  if use_token_type_ids:\n","    model = keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[class_ESG])\n","  else:\n","    model = keras.Model(inputs=[input_ids, attention_mask], outputs=[class_ESG])\n","\n","  model.compile(loss=[\"binary_crossentropy\"], optimizer=optimizer, metrics=['accuracy'])\n","# The new model\n","# https://stackoverflow.com/questions/58565394/what-is-the-difference-between-sparse-categorical-crossentropy-and-categorical-c\n","# I still don't know if it is better sparse or the simple categorical, read above\n","#  model.compile(loss=[\"categorical_crossentropy\", \"categorical_crossentropy\", \"categorical_crossentropy\"], loss_weights=[0.33, 0.33, 0.33], optimizer=optimizer, metrics=['accuracy'])\n","  model.summary()\n","  return model"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5HGiLApDvGLS"},"source":["### Evaluation metrics"]},{"cell_type":"code","metadata":{"id":"auvsPEfRuiqx","executionInfo":{"status":"ok","timestamp":1632472166016,"user_tz":180,"elapsed":10,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}}},"source":["# Average exact match score (accuracy) for a list of answers.\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n","\n","# Evaluation method. Given a test dataframe and a model (with its own parameters), predicts the outputs, optionally prints them, and computes the metrics.\n","def eval(df, model, max_len, tokenizer, use_token_type_ids=True, print_output=False):\n","  #list of predictions\n","  pred_ans=[]\n","  true_ans=[]\n","  if use_token_type_ids:\n","    [input_ids, token_type_ids, attention_mask], class_ESG = generate_samples(df, max_len, use_token_type_ids) \n","    pred_class_ESG = model.predict([input_ids, token_type_ids, attention_mask])\n","  else:\n","    [input_ids, attention_mask], [class_ESG] = generate_samples(df, max_len, use_token_type_ids) \n","    pred_class_ESG = model.predict([input_ids, attention_mask])\n","\n","  for i in range(len(df)):\n","    if max(pred_class_ESG[i]) > 0.5:\n","      true_ans.append(df['gri'].loc[i])\n","      if pred_class_ESG[i][0] > 0.5:\n","        pred_ans.append(200)\n","      elif pred_class_ESG[i][1] > 0.5:\n","        pred_ans.append(300)\n","      elif pred_class_ESG[i][2] > 0.5:\n","        pred_ans.append(400)\n","      else:\n","        print(\"Error no class assigned\\n\")\n","  if print_output:\n","    for i in range(len(df)):\n","      print(\"Sentence: {}\".format(df[\"text\"].loc[i]))\n","      print(\"True category: {}, Prediction 200: {:+.2f}, Prediction 300: {:+.2f}, Prediction 400: {:+.2f}\".format(\n","          df['gri'].loc[i], pred_class_ESG[i][0],pred_class_ESG[i][1],pred_class_ESG[i][2]))\n","\n","  print(\"=======================================\")\n","  print(\"Accuracy:\\t\\t{:+.4f}%\".format(accuracy_score(true_ans, pred_ans)*100))\n","  print(\"F1-score:\\t\\t{:+.4f}%\".format(f1_score(true_ans, pred_ans, average=\"macro\")*100))\n","  print(\"Precision:\\t\\t{:+.4f}%\".format(precision_score(true_ans, pred_ans, average=\"macro\")*100))\n","  print(\"Recall:\\t\\t\\t{:+.4f}%\".format(recall_score(true_ans, pred_ans, average=\"macro\")*100))\n","  return accuracy_score(true_ans, pred_ans), f1_score(true_ans, pred_ans, average=\"macro\"), recall_score(true_ans, pred_ans, average=\"macro\")\n","  "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["6ae129deb3ce4520a1af7795d8a879e7","ded7ad24a3334929a8361406e0e42403","7ede662df1a64dfb910eed135d87955a","c2db5e3e4c0a4d338360eb0171ba1109","81b23ad5ca2143f79ee2b6938195e703","a869f27dd8934d5d8ed402067efb1862","9ce941df24464f7ba9541f129e3f9df7","3d6175c4a4d64ef394c37ddeb2724440","d3592a3189a640d987368eb248fa8fd5","6b15f5b3098943849a2d8f517e143748","e4daa542ada3499aa75b009ff853d4b1","b47bf091e3e546c98e2f843b07f40afc","c6b237d5a6e94e869dfad227d76b699f","28dff05186ab461fa263e924cdaa39fc","2c0b3920c1fd477ca96f9a0692c335fb","fda21886846544909346ebfcffdc2410","03eaa07b19f44f57bbbbfea5aa715fb5","82c392f0cc634063a389ce97fca6a2aa","2ed24fef594d4d54a8f2a0c554bb73a0","656e6797f5084916ac7bbab06de1099b","6a247a17bbc44b43b1c0cc5f92ed0a01","346f2a9cab8144f8b5d03ced9ba3d821","009fe2137f44437c95de6179aa08ad2d","b64dbce3a8be4087ad791677de283aad","154c02f19c594e97bd8ecb1a66058056","46359f1cb8e3458f895caae2ef0550ef","ae91962003d84ddaab495ea764832d75","0933dd9850484954833f0fce901f3f10","41c8933cd5ac4d25951cb832c2a967ef","3072237a87d74386968f95adf5c33012","6302fdd0e5744bbeb4a3ae32fb092b9c","66cfba832c944d909e750fa3f6300fa0","6cb86bdb4c614eef994ef8c727ba9ddf","b713934421ac4baa830195833be1f9f3","9f8d3b15ecc343b88c0fa373eacea8cb","b92eeb31b68342c086f7c3e604a6b162","b85b12b16fb94924af3e3f4fcb590e9e","42297ee68e0b4ce182f64269e9fc552a","da4dcdfcfa644ce083c3b0500f1e6b05","3d1e6689360b4ae5b89b9d2b03b93e7c","2d954dd61a7c46f7834fdafee64f78dc","a755f17dcb3948c68cf898b908b9b7e3","f6a7c9338c7d4880a9f9ca433bb59713","4e0f914fb9b040939b7a0f45948ad528","7deb16dbc6ca49e59b8f7e917d45edcd","1b329b6a57894034b552c385959b0636","300f17232f9c43fb9da6384a129618e4","06844bf750a346e8a77913109e000caf","7c21cd2609374d0d900cde723434ced5","2e7ea03af4534312894e9a1ceca1310a","011455c31b234b26a3c5c9983c50e218","f8765c11ff6046a0adaa1aa6a71bb7c6","95a2a1f8a05c4db4810e79fa3b186f0e","c42360544bb94caa9f26ace5276d8826","a1735dcce47543d398b5cdd45995ced6"]},"id":"PLXGrwCHyYGC","executionInfo":{"status":"ok","timestamp":1632472492896,"user_tz":180,"elapsed":326889,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"8539c9d1-48d2-4979-8074-0ab12dd0c9a2"},"source":["## Let's check the model -- Training\n","use_tpu = True\n","# max_lengths = [256, 384, 512] # Windows with which each model will be trained.\n","max_lengths = [512] # Windows with which each model will be trained.\n","\n","if not os.path.exists(\"weights\"):\n","  os.mkdir(\"weights\")\n","\n","with open(\"summExp1.jsonl\", \"r\") as f:\n","  ts_file = pd.read_json(f,lines=True)\n","\n","# Models which are going to be trained.\n","models = {\n","      # \"bert-large-uncased\": {\"tokenizer\": BertTokenizer, \"encoder\": TFBertModel, \"weights\": \"bert-large-uncased\", \"use_token_type_ids\": True, \"use_pooler\": True} ,\n","    # \"bert-uncased\": {\"tokenizer\": BertTokenizer, \"encoder\": TFBertModel, \"weights\": \"bert-base-uncased\", \"use_token_type_ids\": True, \"use_pooler\": True} ,\n","      \"bert-base-multilingual-uncased\": {\"tokenizer\": BertTokenizer, \"encoder\": TFBertModel, \"weights\": \"bert-base-multilingual-uncased\", \"use_token_type_ids\": True, \"use_pooler\": True} #,\n","## not working  \"roberta-large\": {\"tokenizer\": RobertaTokenizer, \"encoder\": TFRobertaModel, \"weights\": \"roberta-large\", \"use_token_type_ids\": False, \"use_pooler\": True}\n","  #  \"roberta\": {\"tokenizer\": RobertaTokenizer, \"encoder\": TFRobertaModel, \"weights\": \"roberta-base\", \"use_token_type_ids\": False, \"use_pooler\": True},\n","  #  \"electra-base\": {\"tokenizer\": ElectraTokenizer, \"encoder\": TFElectraModel, \"weights\": \"google/electra-base-discriminator\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","  #  \"electra-small\": {\"tokenizer\": ElectraTokenizer, \"encoder\": TFElectraModel, \"weights\": \"google/electra-small-discriminator\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","#  \"electra-large-generator\": {\"tokenizer\": ElectraTokenizer, \"encoder\": TFElectraModel, \"weights\": \"google/electra-large-generator\", \"use_token_type_ids\": False, \"use_pooler\": False}\n","## not working    \"funnel-small\": {\"tokenizer\": FunnelTokenizer, \"encoder\": TFFunnelForTokenClassification, \"weights\": \"funnel-transformer/small\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","## not working (lasthidenstate)    \"funnel-intermediate\": {\"tokenizer\": FunnelTokenizer, \"encoder\": TFFunnelForTokenClassification, \"weights\": \"funnel-transformer/intermediate\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","  #  \"distilbert-uncased\": {\"tokenizer\": DistilBertTokenizer, \"encoder\": TFDistilBertModel, \"weights\": \"distilbert-base-uncased\", \"use_token_type_ids\": False, \"use_pooler\": False} ,\n","    # \"distilbert-cased\": {\"tokenizer\": DistilBertTokenizer, \"encoder\": TFDistilBertModel, \"weights\": \"distilbert-base-cased\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","    # \"distilbert-multilingual\": {\"tokenizer\": DistilBertTokenizer, \"encoder\": TFDistilBertModel, \"weights\": \"distilbert-base-multilingual-cased\", \"use_token_type_ids\": False, \"use_pooler\": False}\n","    # \"albert-base-v2\": {\"tokenizer\": AlbertTokenizer, \"encoder\": TFAlbertModel, \"weights\": \"albert-base-v2\", \"use_token_type_ids\": False, \"use_pooler\": False}\n","    # \"albert-large-v2\": {\"tokenizer\": AlbertTokenizer, \"encoder\": TFAlbertModel, \"weights\": \"albert-large-v2\", \"use_token_type_ids\": False, \"use_pooler\": False}\n","}\n","\n","if not os.path.exists(\"transformers.csv\"):\n","  with open(\"transformers.csv\", \"w\") as f:\n","    f.write(\"Name\\tAccuracy\\tF1\\tLoss-history\\r\\n\")\n","\n","if use_tpu:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","\n","# Train each model for each window length and record the performance on the validation set.\n","for max_len in max_lengths:\n","  for name, model in models.items():\n","    gc.collect()\n","    with open(\"summExp1.jsonl\", \"r\") as f:\n","        ts_file = pd.DataFrame()\n","        ts_file = pd.read_json(f,lines=True)\n","    tokenizer = model[\"tokenizer\"].from_pretrained(model[\"weights\"])\n","\n","    # Each model uses a different tokenizer, so every time, the train/validation dataframe needs to be rebuilt. Albeit slow, this improves randomization.\n","    df = create_dataframe(ts_file, tokenizer, max_len, 30, 0.9, use_token_type_ids=model[\"use_token_type_ids\"])\n","    total = len(df)\n","    validation_len = len(df.where(df[\"split\"] == \"validation\").dropna())\n","    print(\"Total: {}, train: {}, validation: {}, ratio: {}\".format(total, total - validation_len, validation_len, (total - validation_len) / total))\n","    train_df = df.where(df[\"split\"] == \"train\").dropna().drop(\"split\", axis=1).sample(frac=1).reset_index()\n","    val_df = df.where(df[\"split\"] == \"validation\").dropna().drop(\"split\", axis=1).sample(frac=1).reset_index()\n","    \n","    if model[\"use_token_type_ids\"]:\n","      [input_ids, token_type_ids, attention_mask], [class_ESG] = generate_samples(train_df, max_len, use_token_type_ids=True)\n","    else:\n","      [input_ids, attention_mask], [class_ESG] = generate_samples(train_df, max_len, use_token_type_ids=False)\n","\n","    if use_tpu:\n","      with strategy.scope():\n","        encoder = model[\"encoder\"].from_pretrained(model[\"weights\"])\n","        nn = model_topology(encoder, max_len,use_pooler=model[\"use_pooler\"], \n","                            use_token_type_ids=model[\"use_token_type_ids\"])\n","    else:\n","      encoder = model[\"encoder\"].from_pretrained(model[\"weights\"])\n","      nn = model_topology(encoder, max_len,use_pooler=model[\"use_pooler\"],\n","                          use_token_type_ids=model[\"use_token_type_ids\"])\n","    # For the moment, we don't want so use the save model, add \"_2\" to the file name check\n","    if not os.path.exists(\"weights/{}-{}_2.h5\".format(name, max_len)):\n","      print(\"Training {}...\".format(name))\n","      if model[\"use_token_type_ids\"]:\n","        history = nn.fit([input_ids, token_type_ids, attention_mask], class_ESG, batch_size=64, epochs=10, verbose=1)\n","      else:\n","        history = nn.fit([input_ids, attention_mask], class_ESG, batch_size=64, epochs=10, verbose=1)\n","      acc, f1, rec = eval(val_df, nn, max_len, tokenizer, use_token_type_ids=model[\"use_token_type_ids\"])\n","\n","      with open(\"transformers.csv\", \"a\") as f:\n","        f.write(\"{}-{}\\t{}\\t{}\\t{}\\r\\n\".format(name, max_len, acc, f1, history.history[\"loss\"]))\n","\n","      print(\"{}-{}\\t{}\\t{}\\t{}\\r\\n\".format(name, max_len, acc, f1, history.history[\"loss\"]))\n","      nn.save_weights(\"weights/{}-{}_2.h5\".format(name, max_len))\n","    else:\n","      print(\"{} already trained.\".format(name))\n","      nn.load_weights(\"weights/{}-{}_2.h5\".format(name, max_len))\n","      ## Still we need to know how to transfer the load_weights into a variable to get the loss and write\n","      ## on our transformers.csv file\n","      acc, f1, rec = eval(val_df, nn, max_len, tokenizer, use_token_type_ids=model[\"use_token_type_ids\"],\n","                          print_output=True)\n","    with open(\"transformers.csv\", \"a\") as f:\n","      print(\"{}-{}\\t{}\\t{}\\t{}\\r\\n\".format(name, max_len, acc, f1, \"0\"))\n","      #   f.write(\"{}-{}\\t{}\\t{}\\t{}\\tN/A\\r\\n\".format(name, max_len, iou, acc, f1))\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Clearing out eager caches\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Clearing out eager caches\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.74.67.58:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.74.67.58:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ae129deb3ce4520a1af7795d8a879e7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/872k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b47bf091e3e546c98e2f843b07f40afc","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"009fe2137f44437c95de6179aa08ad2d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b713934421ac4baa830195833be1f9f3","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Filename    object\n","GRI         object\n","Text        object\n","Obs         object\n","dtype: object\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["##Warning: token length larger than the maximum (662). Splitting answer into partially overlapped chunks...\n","comparison benefits fulltime temporary employees benefitis stakeholder group benefit description employees brazil operations ergonomics program seeks make every worker comfortable productive workstation welladjusted working conditions making changes needed ergonomics programsocial servicecalisthenics programchronic illness management programdiscounts product purchasesviva sade programprogram womenchild care special help subsidieslife insurance transportparkingdrugstore discount programfree chartered transportrunners projectsale school mate rialsnatura clubwellbeing centerservices conve niencesdescriptionseeks make every worker comfortable productive workstation welladjusted working conditions making changes neededespacio de discusin comprensin resolucin de las cuestiones de orden social de los colaboradorespromotes quality life health work environment helps reduce stressrelated illnessesfor employees family members chronic illnessesa    discount five natura products per monthaimed employees goal stimulating reflection quality life importance prevention promoting good health presentsrecognition length employmentnatura education nurseryadoptionmedical dental planspartial reimbursement cost medicinestelemedicine health movegym subsidyfree productschristmas food vouchershealth centerpersonal support programtempo de casa momento famlia eventsend year company partydescriptionpresents employees mothers fathers toys christmas childrenemployees get party present working natura five years every five years thatscholarships employees family members program revised      fully subsidized children age   years    monthssupport offered adoption processesmedical plan fixed cost employee dental plan also offer checkups employees management level upfor treating cardiovascular diseases diabetes kidney failure cancer liver diseases neurological disorders workrelated musculoskeletal disorders psychiatric disorderseletrocardiogram phone emergency casesprogram encourages physical activity including nutritional medical checkup orientation well advice personal trainerfor relationship managers sales managersfive free products per month management level employees directorsto employeesemergency medical assistance physical therapy rpg ob gyn acupuncture orthopedics nutrition psychologyoffers personal assistance areas finance psychology law among otherstempo de casa length employment momento famlia family time events held cajamarcombined end year celebration employees operational administrative categoriesregular prenatal checkups dedicated medical team medical insurance upgrade postpartum psychological monitoringhosting meetups pregnant women partners family members friendsto cover education costs children disabilitiesvehicles fuel allowance employees senior management level aboveavailable cajamar nasp alphavillemedicine discounts employees payment deducted directly salary    bus lines chartered cost employeestraining running races walks local parks villalobos ibirapuera alphaville e cajamar run professionalswith discounts installments deductible employees salaryfitness training swimming pool extended family members including weekends dancing classes football tournaments multisports court cajamar massages hairdressing waxing manicures special pricesseamstress services laundry shoe repair optician insurance company post office book rental store video store cajamar partnershipsdiscounts perks employees gym home appliances travel agency panetones traditional milanese fruit cake usually consumed christmas time movie theaters theme parks\n","Total: 787, train: 709, validation: 78, ratio: 0.9008894536213469\n","index               int64\n","filename           object\n","text               object\n","gri               float64\n","input_ids          object\n","token_type_ids     object\n","attention_mask     object\n","dtype: object\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7deb16dbc6ca49e59b8f7e917d45edcd","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/999M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f9be68f5d00>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f9be68f5d00>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f9be68f5d00>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f9c054e2290> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f9c054e2290> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING: AutoGraph could not transform <function wrap at 0x7f9c054e2290> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model (TFBertModel)     TFBaseModelOutputWit 167356416   input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 3)            2307        tf_bert_model[0][1]              \n","==================================================================================================\n","Total params: 167,358,723\n","Trainable params: 167,358,723\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Training bert-base-multilingual-uncased...\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=uint8>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=bool>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 3) dtype=bool>]\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=uint8>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=bool>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 3) dtype=bool>]\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stdout","text":["12/12 [==============================] - 136s 5s/step - loss: 0.5022 - accuracy: 0.6333\n","Epoch 2/10\n","12/12 [==============================] - 3s 255ms/step - loss: 0.3484 - accuracy: 0.7743\n","Epoch 3/10\n","12/12 [==============================] - 3s 255ms/step - loss: 0.2805 - accuracy: 0.8237\n","Epoch 4/10\n","12/12 [==============================] - 3s 255ms/step - loss: 0.2397 - accuracy: 0.8646\n","Epoch 5/10\n","12/12 [==============================] - 3s 255ms/step - loss: 0.1776 - accuracy: 0.9111\n","Epoch 6/10\n","12/12 [==============================] - 3s 254ms/step - loss: 0.1498 - accuracy: 0.9041\n","Epoch 7/10\n","12/12 [==============================] - 3s 254ms/step - loss: 0.1346 - accuracy: 0.9140\n","Epoch 8/10\n","12/12 [==============================] - 3s 254ms/step - loss: 0.1151 - accuracy: 0.9351\n","Epoch 9/10\n","12/12 [==============================] - 3s 255ms/step - loss: 0.1115 - accuracy: 0.9337\n","Epoch 10/10\n","12/12 [==============================] - 3s 254ms/step - loss: 0.0885 - accuracy: 0.9450\n","index               int64\n","filename           object\n","text               object\n","gri               float64\n","input_ids          object\n","token_type_ids     object\n","attention_mask     object\n","dtype: object\n"]},{"output_type":"stream","name":"stderr","text":["INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=uint8>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=bool>]\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stdout","text":["=======================================\n","Accuracy:\t\t+85.7143%\n","F1-score:\t\t+73.3333%\n","Precision:\t\t+82.9832%\n","Recall:\t\t\t+70.4308%\n","bert-base-multilingual-uncased-512\t0.8571428571428571\t0.7333333333333333\t[0.5022231340408325, 0.3484392762184143, 0.28050583600997925, 0.23974283039569855, 0.17757312953472137, 0.1497541069984436, 0.13456939160823822, 0.11507279425859451, 0.11154400557279587, 0.08851973712444305]\n","\n","bert-base-multilingual-uncased-512\t0.8571428571428571\t0.7333333333333333\t0\n","\n"]}]}]}