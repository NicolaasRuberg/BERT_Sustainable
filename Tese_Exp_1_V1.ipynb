{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"Tese_Exp_1_V1.ipynb","provenance":[{"file_id":"1MUZOkqiK6y1SAsKpbPOLZuJZvI5bGL2x","timestamp":1626249129862}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"a6e6211e44c4423cbf84d4f625aaac57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_04ed5035609a42fe99547eb62b951e80","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6c71b08504b647a5a3842e9873896429","IPY_MODEL_6b7094a205f64ccbb05579627cf1c234","IPY_MODEL_cf0db95acb3441e3b1ce0019b710a8be"]}},"04ed5035609a42fe99547eb62b951e80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c71b08504b647a5a3842e9873896429":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9e0da15e5adf4c61b89d75d64cfe8354","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_975e9d1188924aa8af81513852920ed0"}},"6b7094a205f64ccbb05579627cf1c234":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_410ed42695164a43b2dccebc6b2b94bd","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":871891,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":871891,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a190ceaa3e2a41e18d850d97fc683ef2"}},"cf0db95acb3441e3b1ce0019b710a8be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bdd8b42ecd4246ca8463b3a0a5eed8c4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 872k/872k [00:00&lt;00:00, 2.45MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89711f1af3a54e8985b9e1d8319b9ec9"}},"9e0da15e5adf4c61b89d75d64cfe8354":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"975e9d1188924aa8af81513852920ed0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"410ed42695164a43b2dccebc6b2b94bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a190ceaa3e2a41e18d850d97fc683ef2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdd8b42ecd4246ca8463b3a0a5eed8c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89711f1af3a54e8985b9e1d8319b9ec9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"86d892002c564082ac80f144f3ac682d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_eff8ae603cad4d31a91a4be91259b065","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_15fd9d2614684953af8cf08d63432717","IPY_MODEL_be3016cd6ce64d81a0fdf185590c6d80","IPY_MODEL_6fb09256ad4c4a79b7c062b7ffad516e"]}},"eff8ae603cad4d31a91a4be91259b065":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"15fd9d2614684953af8cf08d63432717":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9bb0721dca7f462fb8aa1444432f011e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9f3ea3fd11e40b5a8fa3472f344dc93"}},"be3016cd6ce64d81a0fdf185590c6d80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e90f1aacb07a41339ee6fa0570b5e82a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d9fdaca0e0844fb483994b5b2a68217b"}},"6fb09256ad4c4a79b7c062b7ffad516e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ae469ba61d14413e9bedc87a83756b20","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:00&lt;00:00, 1.01kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6b02b4f744cc42bc961840317f828a4e"}},"9bb0721dca7f462fb8aa1444432f011e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a9f3ea3fd11e40b5a8fa3472f344dc93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e90f1aacb07a41339ee6fa0570b5e82a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d9fdaca0e0844fb483994b5b2a68217b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae469ba61d14413e9bedc87a83756b20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6b02b4f744cc42bc961840317f828a4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c05ec69641ca4c0c971505a4577c2b4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1ffa624a7dd7425b93bb256e00bc4cd4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_483950cc7c464d2295aaa8a59c75c573","IPY_MODEL_6d400c740e03419f983132f7a0b5b610","IPY_MODEL_fac6e368458b458a9ee989c61110781f"]}},"1ffa624a7dd7425b93bb256e00bc4cd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"483950cc7c464d2295aaa8a59c75c573":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0f94e9ec410b47b0a60fa14fba08bf20","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9da24186f3224c5e95668a2d23e90906"}},"6d400c740e03419f983132f7a0b5b610":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c85a0b30d97344e6a0999e215e9bc138","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1715180,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1715180,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_901edaeaec4d4c548a4dbee6453a6c7f"}},"fac6e368458b458a9ee989c61110781f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d16c7b3f63ae4ae286846267a2643a42","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.72M/1.72M [00:00&lt;00:00, 6.90MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d91ebc5dc9e4bc9a9effc362a911e9f"}},"0f94e9ec410b47b0a60fa14fba08bf20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9da24186f3224c5e95668a2d23e90906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c85a0b30d97344e6a0999e215e9bc138":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"901edaeaec4d4c548a4dbee6453a6c7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d16c7b3f63ae4ae286846267a2643a42":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9d91ebc5dc9e4bc9a9effc362a911e9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bee07f551503458182e73e33af2ea738":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1ec0ee98c8d402c96fca135d2d11e29","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bac667b9872e4be5ae455d94e9a4c5d0","IPY_MODEL_8ff32097c0fc44be8612f428ee4643db","IPY_MODEL_b8b045d95aff44eba04e0330a340a350"]}},"e1ec0ee98c8d402c96fca135d2d11e29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bac667b9872e4be5ae455d94e9a4c5d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_969f6fbf0a4f4214b1d02a911795d495","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_66a1dff8bba24495a68d6ff015f31993"}},"8ff32097c0fc44be8612f428ee4643db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fb6760a7579c4400a472a4c31cab4950","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_071024c5956b4c238e5c38d417414e64"}},"b8b045d95aff44eba04e0330a340a350":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6c64c95f1a33437eb0448e718e8451f3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 21.7kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33f43c9b145d47cd997c737e11cfbf0b"}},"969f6fbf0a4f4214b1d02a911795d495":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"66a1dff8bba24495a68d6ff015f31993":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb6760a7579c4400a472a4c31cab4950":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"071024c5956b4c238e5c38d417414e64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c64c95f1a33437eb0448e718e8451f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33f43c9b145d47cd997c737e11cfbf0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a4d449e36964a9982f1160d5e85d457":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ef649515dda049b5b3a3a3908a36e945","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e690a682cf8947819c53d570f64aa27f","IPY_MODEL_efb8c29841c44a10b6a001be9f8f941c","IPY_MODEL_ebd3b671df2f49f4810ab66d7a7ca1dc"]}},"ef649515dda049b5b3a3a3908a36e945":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e690a682cf8947819c53d570f64aa27f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea04e3637e16409a8bef965f8c7337ca","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_097d24196ac44f01a7ab14a5f67bd7c6"}},"efb8c29841c44a10b6a001be9f8f941c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ea8d6e1776714fb587a980c469b24c4f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":999358484,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":999358484,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41ff484527f040ae95e4054a681ae1c6"}},"ebd3b671df2f49f4810ab66d7a7ca1dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e95aec29705c44948b9f2c3e7a062fbf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 999M/999M [00:18&lt;00:00, 54.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc8fbe57b40f4fd39e82e5547c19b375"}},"ea04e3637e16409a8bef965f8c7337ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"097d24196ac44f01a7ab14a5f67bd7c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea8d6e1776714fb587a980c469b24c4f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"41ff484527f040ae95e4054a681ae1c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e95aec29705c44948b9f2c3e7a062fbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dc8fbe57b40f4fd39e82e5547c19b375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"p5Vc-7MzQB28"},"source":["# 1st Experiment classifying GRIs into Concepts: 200,300,400\n","\n","> This script is used to train a multiclass classifier using Bert and some other flavors, also we provide the evaluation of each strategy. For better performance we use a TPU backend.\n","\n","\n","> To run on Google Drive, the input data (training and validation) is expected in the folder named SQUAD MATERIAL.\n","\n","OBS.: Need to treat words like im- pact "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RHnncU74lP_","executionInfo":{"status":"ok","timestamp":1632473252149,"user_tz":180,"elapsed":15,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"8dd50d6e-a153-404f-9dc3-ee8ec0c13f65"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 37.8 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"code","metadata":{"id":"aCIb2Njm626-","executionInfo":{"status":"ok","timestamp":1632327669714,"user_tz":180,"elapsed":5,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}}},"source":["#!cat /proc/cpuinfo\n","#!cat /proc/meminfo"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jxuqf1a7EUmD","executionInfo":{"status":"ok","timestamp":1632473269912,"user_tz":180,"elapsed":17770,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"8c143f2d-c342-499a-bc0f-78559b0d13c8"},"source":["!pip install tokenizers\n","!pip install transformers\n","\n","import json\n","import pandas as pd\n","import string\n","import re\n","import gc\n","import os\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import tensorflow.keras.layers as layers\n","\n","!pip install sentencepiece\n","from transformers import BertTokenizer, TFBertModel\n","from transformers import DistilBertTokenizer, TFDistilBertModel\n","from transformers import RobertaTokenizer, TFRobertaModel\n","from transformers import ElectraTokenizer, TFElectraModel\n","# from transformers import FunnelTokenizer, TFFunnelForTokenClassification\n","from transformers import AlbertTokenizer, TFAlbertModel"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tokenizers\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 5.4 MB/s \n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.10.3\n","Collecting transformers\n","  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 69.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 70.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Installing collected packages: sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.45 transformers-4.10.3\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9pZ6AswbNFsM","executionInfo":{"status":"ok","timestamp":1632473293207,"user_tz":180,"elapsed":23301,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"beec09f7-0e0d-4202-cfad-cc5bcb477563"},"source":["# Accessing local drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/NLP_tese/Exp1"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/NLP_tese/Exp1\n"]}]},{"cell_type":"code","metadata":{"id":"c388aDw9OTT4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632473296955,"user_tz":180,"elapsed":2170,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"afa8e26b-406b-4f7d-b86d-4c91279b26fe"},"source":["import nltk\n","from nltk.corpus import stopwords\n","from functools import reduce\n","\n","REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n","GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n","try:\n","    STOPWORDS = set(stopwords.words('english'))\n","except LookupError:\n","    nltk.download('stopwords')\n","    STOPWORDS = set(stopwords.words('english'))\n","def lower(text):\n","    return text.lower()\n","def replace_special_characters(text):\n","    return REPLACE_BY_SPACE_RE.sub(' ', text)\n","def filter_out_uncommon_symbols(text):\n","    return GOOD_SYMBOLS_RE.sub('', text)\n","def remove_stopwords(text):\n","    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n","def strip_text(text):\n","    return text.strip()\n","def remove_GRI(text):\n","    regex = re.compile(r'GRI|gri', re.UNICODE)\n","    return re.sub(regex, '', text)\n","def remove_articles(text):\n","    regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n","    return re.sub(regex, ' ', text)\n"," \n","PREPROCESSING_PIPELINE = [\n","#                          remove_articles,\n","#                          remove_GRI,\n","                          lower,\n","#                          replace_special_characters,\n","#                          filter_out_uncommon_symbols,\n","#                          remove_stopwords,\n","#                          strip_text\n","                          ]\n","# Anchor method\n","def text_prepare(text, filter_methods=None):\n","    \"\"\"\n","    Applies a list of pre-processing functions in sequence (reduce).\n","    Note that the order is important here!\n","    \"\"\"\n","\n","    filter_methods = filter_methods if filter_methods is not None else PREPROCESSING_PIPELINE\n","\n","    return reduce(lambda txt, f: f(txt), filter_methods, text)\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"SIO1YVQKGMFB","executionInfo":{"status":"ok","timestamp":1632473296956,"user_tz":180,"elapsed":9,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}}},"source":["## Implementing our new creat_dataframe function \n","def aggregate_cat(txt):\n","  txt_100 = re.sub('^1[0-9][0-9]\\-[0-9]+', '100', txt.strip())\n","  txt_200 = re.sub('^2[0-9][0-9]\\-[0-9]+', '200', txt_100)\n","  txt_300 = re.sub('^3[0-9][0-9]\\-[0-9]+', '300', txt_200)\n","  txt_400 = re.sub('^4[0-9][0-9]\\-[0-9]+', '400', txt_300)\n","  return (txt_400)\n","\n","def create_dataframe(ds, tokenizer, maxlen=512, stride=30, split=0.9, use_token_type_ids=True):\n","  samples = []\n","  # We have our ds with the format of <Filename,GRI,Text>\n","  #let's start aggregating our 200,300 and 400 categories\n","  print(ds.dtypes)\n","  ds['GRI'] = ds['GRI'].apply(lambda txt: aggregate_cat(txt))\n","  ds['GRI'] = pd.to_numeric(ds['GRI']).astype('int32') \n","  # Let's remove the 100 category\n","  ds.drop(ds[ds['GRI'] == 100].index, inplace=True)\n","  ds = ds.reset_index(drop=True)\n","  ds['GRI'] = ds['GRI'].astype('int32') \n","  # We clean our text data\n","  ds['Text'] = ds['Text'].apply(lambda txt: text_prepare(txt))\n","  ###\n","  for index, row in ds.iterrows():\n","    tmp_a = row['Text']\n","    tmp_gri = row['GRI']\n","    tmp_filename = row['Filename']\n","    tmp_tokens = tokenizer(tmp_a)\n","    tok_len = len(tmp_tokens[\"input_ids\"])\n","    idx = tmp_tokens[\"input_ids\"].index(tokenizer.sep_token_id)\n","    # Split between train and validation according to the data field in the original dataframe.\n","    tmp_split = \"train\" if index < len(ds['Text']) * split else \"validation\"\n","    # If the total length exceeds the window length, the context is split with a partial overlap governed by stride.\n","    if tok_len > maxlen:\n","      print(\"##Warning: token length larger than the maximum ({}). Splitting answer into partially overlapped chunks...\".format(tok_len))\n","      print(tmp_a)\n","    else:\n","      if use_token_type_ids:\n","        samples.append({\"filename\": tmp_filename, \"text\": tmp_a, \"gri\": tmp_gri, \"input_ids\": tmp_tokens[\"input_ids\"], \"token_type_ids\": tmp_tokens[\"token_type_ids\"], \"attention_mask\": tmp_tokens[\"attention_mask\"], \"split\": tmp_split})\n","      else:\n","        samples.append({\"filename\": tmp_filename, \"text\": tmp_a, \"gri\": tmp_gri, \"input_ids\": tmp_tokens[\"input_ids\"], \"attention_mask\": tmp_tokens[\"attention_mask\"], \"split\": tmp_split})\n","\n","  return pd.DataFrame(samples)\n","\n","# Returns tensors for the model, starting from the provided dataframe (which contains prewindowed entries).\n","def generate_samples(df, max_len, use_token_type_ids=True):\n","  input_ids = np.zeros((len(df), max_len), dtype=np.int32)\n","  attention_mask = np.zeros((len(df), max_len), dtype=np.bool)\n","  class_ESG = np.zeros((len(df),3), dtype=np.bool)\n","\n","  print(df.dtypes)\n","  if use_token_type_ids:\n","    token_type_ids = np.zeros((len(df), max_len), dtype=np.uint8)\n","\n","  for i in range(len(df)):\n","    tmp_length = len(df[\"input_ids\"].loc[i])\n","    input_ids[i,:tmp_length] = df[\"input_ids\"].loc[i]\n","    attention_mask[i,:tmp_length] = df[\"attention_mask\"].loc[i]\n","    if use_token_type_ids:\n","      token_type_ids[i,:tmp_length] = df[\"token_type_ids\"].loc[i]\n","    # we want class_ESG with vector(3) with [1,0,0] if 200, [0,1,0]\n","    if df['gri'].loc[i] == 200:\n","      class_ESG[i,0] = 1\n","    elif df['gri'].loc[i] == 300:\n","      class_ESG[i,1] = 1\n","    else :\n","      class_ESG[i,2] = 1\n","  # End for\n","\n","  if use_token_type_ids:\n","    return [input_ids, token_type_ids, attention_mask], [class_ESG]\n","  else:\n","    return [input_ids, attention_mask], [class_ESG]\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OFNNxrmxeg1W"},"source":["### Preprocessing and windowing"]},{"cell_type":"markdown","metadata":{"id":"UzJ298hdel31"},"source":["### Model"]},{"cell_type":"code","metadata":{"id":"lZagq1mCDWJ-","executionInfo":{"status":"ok","timestamp":1632473296956,"user_tz":180,"elapsed":8,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}}},"source":["# Modular model topology. Takes an encoder layer and connects it to text head. \n","# https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n","\n","def model_topology(encoder, max_len=512, use_pooler=True, use_token_type_ids=True):\n","  input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n","  attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n","\n","  if use_token_type_ids:\n","    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n","    transformer = encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n","  else:\n","    transformer = encoder(input_ids, attention_mask=attention_mask)\n","  # we predict 3 classes (200,300,400), so units=3\n","  if use_pooler:\n","    class_ESG = layers.Dense(units=3, activation=\"sigmoid\")(transformer[\"pooler_output\"])\n","  else:\n","    transformer = layers.Flatten()(transformer[\"last_hidden_state\"])\n","    class_ESG = layers.Dense(units=3, activation=\"sigmoid\")(transformer)\n","\n","  optimizer = keras.optimizers.Adam(learning_rate=5e-5) \n","  # From https://towardsdatascience.com/multi-label-multi-class-text-classification-with-bert-transformer-and-keras-c6355eccb63a\n","  # We have this suggestion for the optimizer\n","  # optimizer = Adam( learning_rate=5e-05, epsilon=1e-08, decay=0.01, clipnorm=1.0)\n","\n","  if use_token_type_ids:\n","    model = keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[class_ESG])\n","  else:\n","    model = keras.Model(inputs=[input_ids, attention_mask], outputs=[class_ESG])\n","\n","  model.compile(loss=[\"binary_crossentropy\"], optimizer=optimizer, metrics=['accuracy'])\n","# The new model\n","# https://stackoverflow.com/questions/58565394/what-is-the-difference-between-sparse-categorical-crossentropy-and-categorical-c\n","# I still don't know if it is better sparse or the simple categorical, read above\n","#  model.compile(loss=[\"categorical_crossentropy\", \"categorical_crossentropy\", \"categorical_crossentropy\"], loss_weights=[0.33, 0.33, 0.33], optimizer=optimizer, metrics=['accuracy'])\n","  model.summary()\n","  return model"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5HGiLApDvGLS"},"source":["### Evaluation metrics"]},{"cell_type":"code","metadata":{"id":"auvsPEfRuiqx","executionInfo":{"status":"ok","timestamp":1632473296957,"user_tz":180,"elapsed":8,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}}},"source":["# Average exact match score (accuracy) for a list of answers.\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n","\n","# Evaluation method. Given a test dataframe and a model (with its own parameters), predicts the outputs, optionally prints them, and computes the metrics.\n","def eval(df, model, max_len, tokenizer, use_token_type_ids=True, print_output=False):\n","  #list of predictions\n","  pred_ans=[]\n","  true_ans=[]\n","  if use_token_type_ids:\n","    [input_ids, token_type_ids, attention_mask], class_ESG = generate_samples(df, max_len, use_token_type_ids) \n","    pred_class_ESG = model.predict([input_ids, token_type_ids, attention_mask])\n","  else:\n","    [input_ids, attention_mask], [class_ESG] = generate_samples(df, max_len, use_token_type_ids) \n","    pred_class_ESG = model.predict([input_ids, attention_mask])\n","\n","  for i in range(len(df)):\n","    if max(pred_class_ESG[i]) > 0.5:\n","      true_ans.append(df['gri'].loc[i])\n","      if pred_class_ESG[i][0] > 0.5:\n","        pred_ans.append(200)\n","      elif pred_class_ESG[i][1] > 0.5:\n","        pred_ans.append(300)\n","      elif pred_class_ESG[i][2] > 0.5:\n","        pred_ans.append(400)\n","      else:\n","        print(\"Error no class assigned\\n\")\n","  if print_output:\n","    for i in range(len(df)):\n","      print(\"Sentence: {}\".format(df[\"text\"].loc[i]))\n","      print(\"True category: {}, Prediction 200: {:+.2f}, Prediction 300: {:+.2f}, Prediction 400: {:+.2f}\".format(\n","          df['gri'].loc[i], pred_class_ESG[i][0],pred_class_ESG[i][1],pred_class_ESG[i][2]))\n","\n","  print(\"=======================================\")\n","  print(\"Accuracy:\\t\\t{:+.4f}%\".format(accuracy_score(true_ans, pred_ans)*100))\n","  print(\"F1-score:\\t\\t{:+.4f}%\".format(f1_score(true_ans, pred_ans, average=\"macro\")*100))\n","  print(\"Precision:\\t\\t{:+.4f}%\".format(precision_score(true_ans, pred_ans, average=\"macro\")*100))\n","  print(\"Recall:\\t\\t\\t{:+.4f}%\".format(recall_score(true_ans, pred_ans, average=\"macro\")*100))\n","  return accuracy_score(true_ans, pred_ans), f1_score(true_ans, pred_ans, average=\"macro\"), recall_score(true_ans, pred_ans, average=\"macro\")\n","  "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a6e6211e44c4423cbf84d4f625aaac57","04ed5035609a42fe99547eb62b951e80","6c71b08504b647a5a3842e9873896429","6b7094a205f64ccbb05579627cf1c234","cf0db95acb3441e3b1ce0019b710a8be","9e0da15e5adf4c61b89d75d64cfe8354","975e9d1188924aa8af81513852920ed0","410ed42695164a43b2dccebc6b2b94bd","a190ceaa3e2a41e18d850d97fc683ef2","bdd8b42ecd4246ca8463b3a0a5eed8c4","89711f1af3a54e8985b9e1d8319b9ec9","86d892002c564082ac80f144f3ac682d","eff8ae603cad4d31a91a4be91259b065","15fd9d2614684953af8cf08d63432717","be3016cd6ce64d81a0fdf185590c6d80","6fb09256ad4c4a79b7c062b7ffad516e","9bb0721dca7f462fb8aa1444432f011e","a9f3ea3fd11e40b5a8fa3472f344dc93","e90f1aacb07a41339ee6fa0570b5e82a","d9fdaca0e0844fb483994b5b2a68217b","ae469ba61d14413e9bedc87a83756b20","6b02b4f744cc42bc961840317f828a4e","c05ec69641ca4c0c971505a4577c2b4e","1ffa624a7dd7425b93bb256e00bc4cd4","483950cc7c464d2295aaa8a59c75c573","6d400c740e03419f983132f7a0b5b610","fac6e368458b458a9ee989c61110781f","0f94e9ec410b47b0a60fa14fba08bf20","9da24186f3224c5e95668a2d23e90906","c85a0b30d97344e6a0999e215e9bc138","901edaeaec4d4c548a4dbee6453a6c7f","d16c7b3f63ae4ae286846267a2643a42","9d91ebc5dc9e4bc9a9effc362a911e9f","bee07f551503458182e73e33af2ea738","e1ec0ee98c8d402c96fca135d2d11e29","bac667b9872e4be5ae455d94e9a4c5d0","8ff32097c0fc44be8612f428ee4643db","b8b045d95aff44eba04e0330a340a350","969f6fbf0a4f4214b1d02a911795d495","66a1dff8bba24495a68d6ff015f31993","fb6760a7579c4400a472a4c31cab4950","071024c5956b4c238e5c38d417414e64","6c64c95f1a33437eb0448e718e8451f3","33f43c9b145d47cd997c737e11cfbf0b","8a4d449e36964a9982f1160d5e85d457","ef649515dda049b5b3a3a3908a36e945","e690a682cf8947819c53d570f64aa27f","efb8c29841c44a10b6a001be9f8f941c","ebd3b671df2f49f4810ab66d7a7ca1dc","ea04e3637e16409a8bef965f8c7337ca","097d24196ac44f01a7ab14a5f67bd7c6","ea8d6e1776714fb587a980c469b24c4f","41ff484527f040ae95e4054a681ae1c6","e95aec29705c44948b9f2c3e7a062fbf","dc8fbe57b40f4fd39e82e5547c19b375"]},"id":"PLXGrwCHyYGC","executionInfo":{"status":"ok","timestamp":1632473622320,"user_tz":180,"elapsed":325370,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"65d8b151-e5b8-44bd-e019-2ccb97866fbc"},"source":["## Let's check the model -- Training\n","use_tpu = True\n","# max_lengths = [256, 384, 512] # Windows with which each model will be trained.\n","max_lengths = [512] # Windows with which each model will be trained.\n","\n","if not os.path.exists(\"weights\"):\n","  os.mkdir(\"weights\")\n","\n","with open(\"summExp1.jsonl\", \"r\") as f:\n","  ts_file = pd.read_json(f,lines=True)\n","\n","# Models which are going to be trained.\n","models = {\n","    # \"bert-large-uncased\": {\"tokenizer\": BertTokenizer, \"encoder\": TFBertModel, \"weights\": \"bert-large-uncased\", \"use_token_type_ids\": True, \"use_pooler\": True} ,\n","    # \"bert-uncased\": {\"tokenizer\": BertTokenizer, \"encoder\": TFBertModel, \"weights\": \"bert-base-uncased\", \"use_token_type_ids\": True, \"use_pooler\": True} ,\n","      \"bert-base-multilingual-uncased\": {\"tokenizer\": BertTokenizer, \"encoder\": TFBertModel, \"weights\": \"bert-base-multilingual-uncased\", \"use_token_type_ids\": True, \"use_pooler\": True} #,\n","  #  \"roberta\": {\"tokenizer\": RobertaTokenizer, \"encoder\": TFRobertaModel, \"weights\": \"roberta-base\", \"use_token_type_ids\": False, \"use_pooler\": True},\n","## not working memory    \"roberta-large\": {\"tokenizer\": RobertaTokenizer, \"encoder\": TFRobertaModel, \"weights\": \"roberta-large\", \"use_token_type_ids\": False, \"use_pooler\": True}\n","  # \"electra-base\": {\"tokenizer\": ElectraTokenizer, \"encoder\": TFElectraModel, \"weights\": \"google/electra-base-discriminator\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","  # \"electra-large-generator\": {\"tokenizer\": ElectraTokenizer, \"encoder\": TFElectraModel, \"weights\": \"google/electra-large-generator\", \"use_token_type_ids\": False, \"use_pooler\": False}\n","    # \"electra-small\": {\"tokenizer\": ElectraTokenizer, \"encoder\": TFElectraModel, \"weights\": \"google/electra-small-discriminator\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","## not working    \"funnel-small\": {\"tokenizer\": FunnelTokenizer, \"encoder\": TFFunnelForTokenClassification, \"weights\": \"funnel-transformer/small\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","## not working (lasthidenstate)    \"funnel-intermediate\": {\"tokenizer\": FunnelTokenizer, \"encoder\": TFFunnelForTokenClassification, \"weights\": \"funnel-transformer/intermediate\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","  #  \"distilbert-uncased\": {\"tokenizer\": DistilBertTokenizer, \"encoder\": TFDistilBertModel, \"weights\": \"distilbert-base-uncased\", \"use_token_type_ids\": False, \"use_pooler\": False} ,\n","  #  \"distilbert-cased\": {\"tokenizer\": DistilBertTokenizer, \"encoder\": TFDistilBertModel, \"weights\": \"distilbert-base-cased\", \"use_token_type_ids\": False, \"use_pooler\": False},\n","#   \"distilbert-multilingual\": {\"tokenizer\": DistilBertTokenizer, \"encoder\": TFDistilBertModel, \"weights\": \"distilbert-base-multilingual-cased\", \"use_token_type_ids\": False, \"use_pooler\": False}\n","  # \"albert-base-v2\": {\"tokenizer\": AlbertTokenizer, \"encoder\": TFAlbertModel, \"weights\": \"albert-base-v2\", \"use_token_type_ids\": False, \"use_pooler\": False}\n","    # \"albert-large-v2\": {\"tokenizer\": AlbertTokenizer, \"encoder\": TFAlbertModel, \"weights\": \"albert-large-v2\", \"use_token_type_ids\": False, \"use_pooler\": False}\n","}\n","\n","if not os.path.exists(\"transformers.csv\"):\n","  with open(\"transformers.csv\", \"w\") as f:\n","    f.write(\"Name\\tAccuracy\\tF1\\tLoss-history\\r\\n\")\n","\n","if use_tpu:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","\n","# Train each model for each window length and record the performance on the validation set.\n","for max_len in max_lengths:\n","  for name, model in models.items():\n","    gc.collect()\n","    with open(\"summExp1.jsonl\", \"r\") as f:\n","        ts_file = pd.DataFrame()\n","        ts_file = pd.read_json(f,lines=True)\n","    tokenizer = model[\"tokenizer\"].from_pretrained(model[\"weights\"])\n","\n","    # Each model uses a different tokenizer, so every time, the train/validation dataframe needs to be rebuilt. Albeit slow, this improves randomization.\n","    df = create_dataframe(ts_file, tokenizer, max_len, 30, 0.9, use_token_type_ids=model[\"use_token_type_ids\"])\n","    total = len(df)\n","    validation_len = len(df.where(df[\"split\"] == \"validation\").dropna())\n","    print(\"Total: {}, train: {}, validation: {}, ratio: {}\".format(total, total - validation_len, validation_len, (total - validation_len) / total))\n","    train_df = df.where(df[\"split\"] == \"train\").dropna().drop(\"split\", axis=1).sample(frac=1).reset_index()\n","    val_df = df.where(df[\"split\"] == \"validation\").dropna().drop(\"split\", axis=1).sample(frac=1).reset_index()\n","    \n","    if model[\"use_token_type_ids\"]:\n","      [input_ids, token_type_ids, attention_mask], [class_ESG] = generate_samples(train_df, max_len, use_token_type_ids=True)\n","    else:\n","      [input_ids, attention_mask], [class_ESG] = generate_samples(train_df, max_len, use_token_type_ids=False)\n","\n","    if use_tpu:\n","      with strategy.scope():\n","        encoder = model[\"encoder\"].from_pretrained(model[\"weights\"])\n","        nn = model_topology(encoder, max_len,use_pooler=model[\"use_pooler\"], \n","                            use_token_type_ids=model[\"use_token_type_ids\"])\n","    else:\n","      encoder = model[\"encoder\"].from_pretrained(model[\"weights\"])\n","      nn = model_topology(encoder, max_len,use_pooler=model[\"use_pooler\"],\n","                          use_token_type_ids=model[\"use_token_type_ids\"])\n","    # For the moment, we don't want so use the save model, add \"_2\" to the file name check\n","    if not os.path.exists(\"weights/{}-{}.h5\".format(name, max_len)):\n","      print(\"Training {}...\".format(name))\n","      if model[\"use_token_type_ids\"]:\n","        history = nn.fit([input_ids, token_type_ids, attention_mask], class_ESG, batch_size=64, epochs=10, verbose=1)\n","      else:\n","        history = nn.fit([input_ids, attention_mask], class_ESG, batch_size=64, epochs=10, verbose=1)\n","      acc, f1, rec = eval(val_df, nn, max_len, tokenizer, use_token_type_ids=model[\"use_token_type_ids\"])\n","\n","      with open(\"transformers.csv\", \"a\") as f:\n","        f.write(\"{}-{}\\t{}\\t{}\\t{}\\r\\n\".format(name, max_len, acc, f1, history.history[\"loss\"]))\n","\n","      print(\"{}-{}\\t{}\\t{}\\t{}\\r\\n\".format(name, max_len, acc, f1, history.history[\"loss\"]))\n","      nn.save_weights(\"weights/{}-{}.h5\".format(name, max_len))\n","    else:\n","      print(\"{} already trained.\".format(name))\n","      nn.load_weights(\"weights/{}-{}.h5\".format(name, max_len))\n","      ## Still we need to know how to transfer the load_weights into a variable to get the loss and write\n","      ## on our transformers.csv file\n","      acc, f1, rec = eval(val_df, nn, max_len, tokenizer, use_token_type_ids=model[\"use_token_type_ids\"],\n","                          print_output=True)\n","    with open(\"transformers.csv\", \"a\") as f:\n","      print(\"{}-{}\\t{}\\t{}\\t{}\\r\\n\".format(name, max_len, acc, f1, \"0\"))\n","      #   f.write(\"{}-{}\\t{}\\t{}\\t{}\\tN/A\\r\\n\".format(name, max_len, iou, acc, f1))\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Clearing out eager caches\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Clearing out eager caches\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.61.208.10:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.61.208.10:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6e6211e44c4423cbf84d4f625aaac57","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/872k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86d892002c564082ac80f144f3ac682d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c05ec69641ca4c0c971505a4577c2b4e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bee07f551503458182e73e33af2ea738","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["Filename    object\n","GRI         object\n","Text        object\n","Obs         object\n","dtype: object\n","##Warning: token length larger than the maximum (693). Splitting answer into partially overlapped chunks...\n","the income received by the communities during the year exceeded r$ 10 million. that is 55% higher than the amount received in 2015 and, in ad- dition to payment for supplies (r$ 5.8 million), it included the sharing of benefits derived from access to traditional knowledge (r$ 3.07 million), support for community infrastructure, training and payment for use of their image.  we have measured the positive impacts created by our relationship with local families, such as income gen- eration through the purchase of in- puts, investment in developing higher value-added production chains and transfer of technical skills through the training we provide. now that they are much better organized, the communi- ties are entering into partnerships with other companies, as well as natura, to supply inputs obtained from the brazil- ian biodiversity. this development was achieved using a sustainable produc- tion and commercial model. we have also invested in improving the productivity of these communities and adding value to their supplies, by upgrading the infrastructure of two extraction units (one in the mid-juru√° region and the other in the northeast of par√°) and thereby improving the quality to the oil and butter produced. we have continued with our training programs in the fields of health, safety, good management practices and or- ganization management, training 545 people in 2016. also in 2016, 100% of supplier commu- nities were audited by our socio-bio- diversity chain verification system, developed jointly with the uebt (union for ethical biotrade). this procedure looks into labor issues, organization management and good production practices, and ensures the tracking of production chains, which is one of our greatest challenges. this verification is ongoing, since the families need to de- velop a system to provide documenta- tion confirming the origin of all inputs. the audits are performed annually in each of the communities, generating action plans that are monitored until the next audit. once a year, the communities partici- pate in the qlicar award - which distin- guishes natura suppliers - in the bio- qlicar category. the award goes to the most noteworthy community, the one that has shown the greatest evolution in several categories revolving around quality and good practices. the bioqli- car ratings underwent some changes in 2016, and the calculation now takes into consideration the ratings provided by the verification system, as well as an indi- cator that measures the planned volume of production and delivery deadline. the communities achieved a 3.93 rat- ing in 2016. this index, which used to be a part of bioqlicar but is now an element of the verification system, ad- vanced slightly in comparison to the previous year‚äôs figure, of 3.62. the rat- ing is weighted, along with the otif (on time in full) assessment rating of the community. the improvement is due to the communities‚äô improved audit rat- ings, as well as greater compliance with the action plans during 2016, which also increases the community‚äôs rating throughout the year. there was also an improvement in the otif rating, com- pared to 2015, due to better delivery planning, both by natura and by the communities, and greater investment in chain infrastructure.56\n","##Warning: token length larger than the maximum (683). Splitting answer into partially overlapped chunks...\n","no  ‚äì total number of species included on the iucn red list and on other conservation lists 1 2014 2015 2016 critically endangered - - - endangered virola surinamensis* (iucn) ‚äì ucuuba virola surinamensis (iucn) ‚äì ucuuba virola surinamensis (iucn and env. min) ‚äì ucuuba pinus elliottii (iucn) ‚äì slash pine euphorbia cerifera (cites) ‚äì candelila euphorbia cerifera (cites) ‚äì candelilla vulnerable bertholletia excelsa (iucn and env. min) - brazil nut vitellaria paradoxa (iucn) - shea tree bertholletia excelsa (iucn and env. min) - brazil nut bertholletia excelsa (iucn and env. min) ‚äì brazil nut vitellaria paradoxa (iucn) ‚äì shea tree vitellaria paradoxa (iucn) ‚äì shea tree santalum album (iucn)* - white sandalwood near threatened ilex paraguariensis (iucn) - paraguay tea ilex paraguariensis (iucn) ‚äì paraguay tea ilex paraguariensis (iucn) ‚äì paraguay tea least concern - - cyperus articulatus (iucn) ‚äì piri piri pinus elliottii (iucn) ‚äì slash pine bulnesia sarmientoi (cites and  iucn) ‚äì holy wood1. plant species that are at risk of extinction, be they native to brazil or exotic (imported and grown in brazil) which are used in natura product lines. conservation projects are in place, in partnership with research institutions and direct suppliers, to protect the species from brazilian biodiversity. for the brazil nut and paraguay tea, two conservation projects have been carried out, in partnership with embrapa. likewise, we have just concluded a conservation project, in partnership with ufscar (federal university of s√£o carlos) to protect ucuuba trees, by collecting its  fruit without cutting them down. we also support the adoption of agroforestry systems for the production of brazil nuts, ucuuba and piri piri in communities in the amazon. paraguay tea is off the list of brazilian flora that are at risk of extinction. on the other hand, piri piri has been placed, for the first time, on the list of the iucn (international union for conservation of nature) and is a species whose organic chain was developed by natura. the slash pine species of pinus, used in fragrance formulas, is obtained from a planted forest whose origin is traceable, as guaranteed by the supplier. in the case of the shea tree, the supplier participates in the global shea alliance, a movement aimed at promoting the sustainability of this production chain. as for candelilla and holy wood, both feature on the cites (convention on international trade in endangered species of wild fauna and flora) list, but the supplier complies with international legislation, and possesses the necessary cites certification. the sandalwood comes from sri lanka, a country that follows strict species protection and conservation policies, and has its sourcing guaranteed by the supplier. furthermore, we have received uebt (union for ethical biotrade) certifications for 14 amazon supplier communities, thereby reinforcing our commitment to ethical sourcing.\n","##Warning: token length larger than the maximum (910). Splitting answer into partially overlapped chunks...\n","supplier communities , , ,  every year, we broaden and strength- en our relationship with the commu- nities that supply our natural inputs. we maintain links with 33 local com- munities, three of which were included in 2016. together, they represent 2,841 families. around 75% of these business partners are located in the amazon region, totaling 27 communities and 2,119 families. the other communities we maintain relationships with are lo- cated in different parts of brazil (see map showing the location of all suppli- er communities here ) two of the three new supplier commu- nities are situated on maraj√≥ island (par√° state), a new area of operations for natura. these new partnerships were required to expand the sourcing of certain bioactive ingredients, such as ucuuba, murumuru and andiroba (all types of plant), enabling us to in- crease the proportion of these inputs in our soaps. the income received by the commu- nities during the year exceeded r$ 10 million. that is 55% higher than the amount received in 2015 and, in ad- dition to payment for supplies (r$ 5.8 million), it included the sharing of ben-2. efits derived from access to traditional knowledge (r$ 3.07 million), support for community infrastructure, training and payment for use of their image. 203-1 we have measured the positive im- pacts created by our relationship with local families, such as income gen- eration through the purchase of in- puts, investment in developing higher value-added production chains and transfer of technical skills through the training we provide. now that they are much better organized, the communi- ties are entering into partnerships with other companies, as well as natura, to supply inputs obtained from the brazil- ian biodiversity. this development was achieved using a sustainable produc- tion and commercial model.\n","we have also invested in improving the productivity of these communities and adding value to their supplies, by upgrading the infrastructure of two extraction units (one in the mid-juruá region and the other in the northeast of pará) and thereby improving the quality to the oil and butter produced. we have continued with our training programs in the fields of health, safety, good management practices and or- ganization management, training 545 people in 2016.\n","also in 2016, 100% of supplier commu- nities were audited by our socio-bio- diversity chain verification system, developed jointly with the uebt (union for ethical biotrade). this procedure looks into labor issues, organization management and good production practices, and ensures the tracking of production chains, which is one of our\n","greatest challenges. this verification is ongoing, since the families need to de- velop a system to provide documenta- tion confirming the origin of all inputs. the audits are performed annually in each of the communities, generating action plans that are monitored until the next audit.\n","once a year, the communities partici- pate in the qlicar award - which distin- guishes natura suppliers - in the bio- qlicar category. the award goes to the most noteworthy community, the one that has shown the greatest evolution in several categories revolving around quality and good practices. the bioqli- car ratings underwent some changes in 2016, and the calculation now takes into consideration the ratings provided by the verification system, as well as an indi- cator that measures the planned volume of production and delivery deadline.\n","the communities achieved a 3.93 rat- ing in 2016. this index, which used to be a part of bioqlicar but is now an element of the verification system, ad- vanced slightly in comparison to the previous year’s figure, of 3.62. the rat- ing is weighted, along with the otif (on time in full) assessment rating of the community. the improvement is due to the communities’ improved audit rat- ings, as well as greater compliance with the action plans during 2016, which also increases the community’s rating throughout the year. there was also an improvement in the otif rating, com- pared to 2015, due to better delivery planning, both by natura and by the communities, and greater investment in chain infrastructure\n","##Warning: token length larger than the maximum (896). Splitting answer into partially overlapped chunks...\n","‚äì comparison between benefits of full-time and temporary employees benefitis stakeholder group benefit description all employees in brazil operations ergonomics program seeks to make every worker comfortable and productive in his or her workstation and well-adjusted to their working conditions, making changes if needed. ergonomics program\n","social service\n","calisthenics program\n","chronic illness management program\n","discounts on product purchases\n","viva saúde program\n","program for women\n","child care and special help subsidies\n","life insurance transport\n","parking\n","drugstore discount program\n","free chartered transport\n","runners project\n","sale of school mate- rials\n","natura club\n","well-being center\n","services and conve- niences\n","description\n","seeks to make every worker comfortable and productive in his or her workstation and well-adjusted to their working conditions, making changes if needed.\n","espacio de discusión, comprensión y resolución de las cuestiones de orden social de los colaboradores.\n","promotes quality of life and health in the work environment and helps reduce stress-related illnesses.\n","for employees and family members of those with chronic illnesses.\n","a 40% discount in up to five natura products per month.\n","aimed at all employees, with the goal of stimulating a reflection on quality of life and the importance of prevention and promoting good health. presents\n","recognition of length of employment\n","natura education nursery\n","adoption\n","medical and dental plans\n","partial reimbursement of the cost of medicines\n","telemedicine health on the move\n","gym subsidy\n","free products\n","christmas food vouchers\n","health center\n","personal support program\n","tempo de casa and momento família events\n","end of the year company party\n","description\n","presents for employees’ mothers and fathers and toys at christmas for their children.\n","employees get a party and a present when they have been working for natura for five years, and then again every five years after that.\n","scholarships for employees and family members (the program is being revised in 2017).\n","fully subsidized for children up to the age of 2 years and 11 months.\n","support offered during adoption processes.\n","medical plan, with no fixed cost for the employee, and a dental plan. we also offer check-ups for employees from management level up.\n","for treating cardiovascular diseases, diabetes, kidney failure, cancer, liver diseases, neurological disorders, work-related musculoskeletal disorders and psychiatric disorders.\n","eletrocardiogram by phone, in emergency cases.\n","program that encourages physical activity, including nutritional, and medical check-up and orientation, as well as advice from a personal trainer.\n","for relationship managers and sales managers.\n","five free products per month for management level employees and directors.\n","to all employees.\n","emergency medical assistance, physical therapy, rpg, ob/gyn, acupuncture, orthopedics, nutrition and psychology.\n","offers personal assistance in the areas of finance, psychology and law, among others.\n","tempo de casa (length of employment) and momento família (family time) events are held in cajamar.\n","combined end of the year celebration for employees of the operational and administrative categories.\n","regular pre-natal check-ups by a dedicated medical team, medical insurance upgrade and postpartum psychological monitoring.\n","hosting of meet-ups for pregnant women and their partners and/or other family members or friends.\n","to cover education costs of children with disabilities.\n","vehicles and a fuel allowance for employees at senior management level and above.\n","available at cajamar, nasp and alphaville.\n","medicine discounts for all employees with payment deducted directly from their salary.\n","140 bus lines chartered at no cost to employees.\n","training for running races and walks in local parks (villa-lobos, ibirapuera, alphaville e cajamar), run by professionals.\n","with discounts and installments deductible from employee’s salary.\n","fitness training, swimming pool (extended to family members, including on weekends), dancing classes, football tournaments and multi-sports court (cajamar).\n","massages, hairdressing, waxing and manicures, at special prices.\n","seamstress services, laundry, shoe repair, optician, insurance company, post office and book rental store and video store (cajamar).\n","                                     \n","partnerships\n","discounts and/or perks for employees (gym, home appliances, travel agency, panetones - traditional milanese fruit cake usually consumed during christmas time, - movie theaters and theme parks).\n","##Warning: token length larger than the maximum (908). Splitting answer into partially overlapped chunks...\n","supplier communities , , ,  every year, we broaden and strength- en our relationship with the commu- nities that supply our natural inputs. we maintain links with 33 local com- munities, three of which were included in 2016. together, they represent 2,841 families. around 75% of these business partners are located in the amazon region, totaling 27 communities and 2,119 families. the other communities we maintain relationships with are lo- cated in different parts of brazil (see map showing the location of all suppli- er communities here ) two of the three new supplier commu- nities are situated on maraj√≥ island (par√° state), a new area of operations for natura. these new partnerships were required to expand the sourcing of certain bioactive ingredients, such as ucuuba, murumuru and andiroba (all types of plant), enabling us to in- crease the proportion of these inputs in our soaps. the income received by the commu- nities during the year exceeded r$ 10 million. that is 55% higher than the amount received in 2015 and, in ad- dition to payment for supplies (r$ 5.8 million), it included the sharing of ben-efits derived from access to traditional knowledge (r$ 3.07 million), support for community infrastructure, training and payment for use of their image. 203-1 we have measured the positive im- pacts created by our relationship with local families, such as income gen- eration through the purchase of in- puts, investment in developing higher value-added production chains and transfer of technical skills through the training we provide. now that they are much better organized, the communi- ties are entering into partnerships with other companies, as well as natura, to supply inputs obtained from the brazil- ian biodiversity. this development was achieved using a sustainable produc- tion and commercial model.\n","we have also invested in improving the productivity of these communities and adding value to their supplies, by upgrading the infrastructure of two extraction units (one in the mid-juruá region and the other in the northeast of pará) and thereby improving the quality to the oil and butter produced. we have continued with our training programs in the fields of health, safety, good management practices and or- ganization management, training 545 people in 2016.\n","also in 2016, 100% of supplier commu- nities were audited by our socio-bio- diversity chain verification system, developed jointly with the uebt (union for ethical biotrade). this procedure looks into labor issues, organization management and good production practices, and ensures the tracking of production chains, which is one of our\n","greatest challenges. this verification is ongoing, since the families need to de- velop a system to provide documenta- tion confirming the origin of all inputs. the audits are performed annually in each of the communities, generating action plans that are monitored until the next audit.\n","once a year, the communities partici- pate in the qlicar award - which distin- guishes natura suppliers - in the bio- qlicar category. the award goes to the most noteworthy community, the one that has shown the greatest evolution in several categories revolving around quality and good practices. the bioqli- car ratings underwent some changes in 2016, and the calculation now takes into consideration the ratings provided by the verification system, as well as an indi- cator that measures the planned volume of production and delivery deadline.\n","the communities achieved a 3.93 rat- ing in 2016. this index, which used to be a part of bioqlicar but is now an element of the verification system, ad- vanced slightly in comparison to the previous year’s figure, of 3.62. the rat- ing is weighted, along with the otif (on time in full) assessment rating of the community. the improvement is due to the communities’ improved audit rat- ings, as well as greater compliance with the action plans during 2016, which also increases the community’s rating throughout the year. there was also an improvement in the otif rating, com- pared to 2015, due to better delivery planning, both by natura and by the communities, and greater investment in chain infrastructure\n","##Warning: token length larger than the maximum (897). Splitting answer into partially overlapped chunks...\n","every year, we broaden and strength- en our relationship with the commu- nities that supply our natural inputs. we maintain links with 33 local com- munities, three of which were included in 2016. together, they represent 2,841 families. around 75% of these business partners are located in the amazon region, totaling 27 communities and 2,119 families. the other communities we maintain relationships with are lo- cated in different parts of brazil (see map showing the location of all suppli- er communities here)\n","two of the three new supplier commu- nities are situated on marajó island (pará state), a new area of operations for natura. these new partnerships were required to expand the sourcing of certain bioactive ingredients, such as ucuuba, murumuru and andiroba (all types of plant), enabling us to in- crease the proportion of these inputs in our soaps.\n","the income received by the commu- nities during the year exceeded r$ 10 million. that is 55% higher than the amount received in 2015 and, in ad- dition to payment for supplies (r$ 5.8 million), it included the sharing of benefits derived from access to traditional knowledge (r$ 3.07 million), support for community infrastructure, training and payment for use of their image.  we have measured the positive im- pacts created by our relationship with local families, such as income gen- eration through the purchase of in- puts, investment in developing higher value-added production chains and transfer of technical skills through the training we provide. now that they are much better organized, the communi- ties are entering into partnerships with other companies, as well as natura, to supply inputs obtained from the brazil- ian biodiversity. this development was achieved using a sustainable produc- tion and commercial model. we have also invested in improving the productivity of these communities and adding value to their supplies, by upgrading the infrastructure of two extraction units (one in the mid-juru√° region and the other in the northeast of par√°) and thereby improving the quality to the oil and butter produced. we have continued with our training programs in the fields of health, safety, good management practices and or- ganization management, training 545 people in 2016. also in 2016, 100% of supplier commu- nities were audited by our socio-bio- diversity chain verification system, developed jointly with the uebt (union for ethical biotrade). this procedure looks into labor issues, organization management and good production practices, and ensures the tracking of production chains, which is one of our greatest challenges. this verification is ongoing, since the families need to de- velop a system to provide documenta- tion confirming the origin of all inputs. the audits are performed annually in each of the communities, generating action plans that are monitored until the next audit. once a year, the communities partici- pate in the qlicar award - which distin- guishes natura suppliers - in the bio- qlicar category. the award goes to the most noteworthy community, the one that has shown the greatest evolution in several categories revolving around quality and good practices. the bioqli- car ratings underwent some changes in 2016, and the calculation now takes into consideration the ratings provided by the verification system, as well as an indi- cator that measures the planned volume of production and delivery deadline. the communities achieved a 3.93 rat- ing in 2016. this index, which used to be a part of bioqlicar but is now an element of the verification system, ad- vanced slightly in comparison to the previous year‚äôs figure, of 3.62. the rat- ing is weighted, along with the otif (on time in full) assessment rating of the community. the improvement is due to the communities‚äô improved audit rat- ings, as well as greater compliance with the action plans during 2016, which also increases the community‚äôs rating throughout the year. there was also an improvement in the otif rating, com- pared to 2015, due to better delivery planning, both by natura and by the communities, and greater investment in chain infrastructure.\n","##Warning: token length larger than the maximum (812). Splitting answer into partially overlapped chunks...\n","proportion of spending on locally-based suppliers ‚äì brazil griprocurement agriculture commodities 2015 2016 2017 2015 2016 2017 2015 2016 2017 brazil al 0.00% 0.016% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% am 0.00% 0.16% 0.05% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% ba 0.00% 0.18% 0.04% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% ce 0.00% 0.05% 0.02% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% df 0.00% 0.07% 0.02% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% es 0.00% 0.07% 0.02% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% go 0.00% 4.16% 1.21% 20.80% 18.50% 17.43% 19.42% 15.62% 26.70% ma 0.00% 0.01% 0.01% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% mg 0.00% 2.39% 2.50% 6.40% 6.90% 4.85% 11.87% 9.60% 9.64% ms 0.00% 0.39% 0.12% 2.20% 2.40% 2.51% 3.21% 2.24% 4.24% mt 0.00% 3.92% 1.76% 16.10% 15.70% 18.30% 18.23% 18.56% 19.02% pa 0.00% 0.15% 0.05% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% pe 0.00% 1.48% 0.44% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% pi 0.00% 0.01% 0.01% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% pr 0.00% 10.05% 6.11% 21.40% 21.80% 22.31% 28.48% 33.71% 12.72% rj 0.00% 0.27% 0.08% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% rn 0.00% 0.03% 0.01% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% rs 0.00% 6.09% 3.41% 13.20% 12.60% 13.35% 14.31% 13.83% 21.52% sc 0.00% 10.08% 7.50% 19.90% 18.80% 21.25% 4.48% 6.44% 6.20% sp 0.00% 2.12% 3.34% 0.00% 0.00% 0.00% 0.00% 0.00% 0.00% latin america argentina nd 86.4% 87.4% nd 0.70% 0.70% nd 90.42% 99.40% brf annual and sustainability report 2017 164\n","##Warning: token length larger than the maximum (516). Splitting answer into partially overlapped chunks...\n","investments made in recent years have focused on innovation and human capital management, a process conducted based on viva brf attributes and on the guidelines of our strategy, valuing meritocracy, multiculturalism, innovation and high performance and the search for a more entrepreneurial vision in each professional.  the most recent survey conducted in 2016 had 84% engagement. connection and engagement of employees with the culture are monitored through regular surveys and annually though the high performance cycle. gri  we are one of the largest employers in the food sector in brazil and we prioritize the hiring of local professionals in our national and international operations.  in 2017, more than 100,000 employees were part of brf's workforce including direct employees, outsourced employees, interns and apprentices (see more details in the attachment). gri  we have in place a business model and an organizational culture that value and foster the plurality of ideas.  gender, race, and religion do not influence the hiring of professionals, their pay, or the day-to-day relationship.  we attract and select people based on their competencies and diversity. salaries are in line with market standards and with the professional's performance and length of service (read more in attachments). gri ,  therefore, we promote a work environment that is free from any form of discrimination, presenting equal opportunities strictly based on technical competence and individual performance.  adopting a strategy that favors low turnover and talent retention is extremely relevant for the health of a company.  however, this has been an increasingly complex task since the employment relations have undergone significant changes over the years and the external environment is constantly changing. gri 103|401  this way, management of turnover and people engagement are critical for the stability of brf, which are influenced by the economic outlook and the highly competitive nature of our business. the efforts undertaken by our units are aimed at people retention and efficient management of the workforce.  results can be verified through turnover rates, which have shown gradual decline over the years, especially in brazil, the country that accounts for 82% of our workforce. the turnover rate dropped from 28.21% in 2015 and 21.33% in 2016 to 17.80% in 2017 (see more details in the attachment). gri 103|401,17.8% was the turnover rate in 2017, significantly lower than the rate of 28.21% recorded in 2015\n","##Warning: token length larger than the maximum (516). Splitting answer into partially overlapped chunks...\n","investments made in recent years have focused on innovation and human capital management, a process conducted based on viva brf attributes and on the guidelines of our strategy, valuing meritocracy, multiculturalism, innovation and high performance and the search for a more entrepreneurial vision in each professional.  the most recent survey conducted in 2016 had 84% engagement. connection and engagement of employees with the culture are monitored through regular surveys and annually though the high performance cycle. gri  we are one of the largest employers in the food sector in brazil and we prioritize the hiring of local professionals in our national and international operations.  in 2017, more than 100,000 employees were part of brf's workforce including direct employees, outsourced employees, interns and apprentices (see more details in the attachment). gri  we have in place a business model and an organizational culture that value and foster the plurality of ideas.  gender, race, and religion do not influence the hiring of professionals, their pay, or the day-to-day relationship.  we attract and select people based on their competencies and diversity. salaries are in line with market standards and with the professional's performance and length of service (read more in attachments). gri ,  therefore, we promote a work environment that is free from any form of discrimination, presenting equal opportunities strictly based on technical competence and individual performance.  adopting a strategy that favors low turnover and talent retention is extremely relevant for the health of a company.  however, this has been an increasingly complex task since the employment relations have undergone significant changes over the years and the external environment is constantly changing. gri 103|401  this way, management of turnover and people engagement are critical for the stability of brf, which are influenced by the economic outlook and the highly competitive nature of our business. the efforts undertaken by our units are aimed at people retention and efficient management of the workforce.  results can be verified through turnover rates, which have shown gradual decline over the years, especially in brazil, the country that accounts for 82% of our workforce. the turnover rate dropped from 28.21% in 2015 and 21.33% in 2016 to 17.80% in 2017 (see more details in the attachment). gri 103|401,17.8% was the turnover rate in 2017, significantly lower than the rate of 28.21% recorded in 2015\n","##Warning: token length larger than the maximum (610). Splitting answer into partially overlapped chunks...\n","| our industrial and mining operations are located in municipalities in the interior of the states of s√£o paulo (plant) and minas gerais. the identified socio-environmental and economic impacts on the local communities of these territories are distinct, due to the different activities that we conduct in each locality. in the communities impacted by the mining activities, the main environmental impacts identified relate to deforestation to create space for the mining operation and dust caused by the movement of trucks transporting bauxite. to mitigate the impacts of the removal of vegetation for the extraction of the ore, we have a program to rehabilitate and recover the mined areas, developed in partnership with local universities, which guarantees that the soil is returned in good physical and chemical conditions for planting coffee, eucalyptus or pasture, or for the recomposition of the native vegetation (find out more about how we operate, on page 33). to mitigate dust levels, we have the practice of dampening the earth tracks used by the trucks loaded with bauxite and the mining machines. this dampening procedure is done using water tank trucks. also, around the mines, we have equipment that control the air quality continually, enabling timely actions to be carried out in critical situations. to inform the local populations about our good management practices, we have developed an environmental education program (eep), with educational actions for the internal and external publics (see more on page 32). in the municipality of alum√≠nio, where our plant is located, we identified that one of the main impacts of our activities is the risk of economic dependence on the plant. to mitigate this risk, we invested in social projects that help to empower the local population. one such project is the redes program, which promotes the strengthening of inclusive production chains capable of generating income for the community (see more on page 56). in terms of environmental impacts, the main aspects highlighted by the communities relate to the pruning of trees and conservation of areas of native forest that exist around the factory. we have a team that seeks to carry out this work in preventative form, but we also seek to act promptly when we receive notices and alerts from local residents. the communities impacted by our activities can access, via the institutional website of cba, a communication channel where they can submit complaints. other forms of learning about and evaluating the demands of society are reports received directly by the units, which are forwarded to the areas responsible, so that the necessary measures can be taken.419-1 | amounts paid out in fines, infractions and judicial decisions relating to socio- economic aspects totaled r$19.1 million; of this figure, 99.6% relates to agreements and compensations for labor-related lawsuits. the company monitors the lawsuits in progress via a computerized system.\n","##Warning: token length larger than the maximum (661). Splitting answer into partially overlapped chunks...\n","|, , , , , direct economic impact, local communities| social investment in brazil is coordinated by the embraer institute for education and research, which for more than 15 years promotes educa- tion-related projects, engagement with civil soci- ety and the historic preservation of the country‚äôs aeronautical industry. the main initiatives include the juarez wan- derley (s√£o jos√© dos campos, s√£o paulo) and casimiro montenegro filho (botucatu, s√£o paulo) schools, which offer free, full-time high school education to students coming from public schools and whose household income is lower than 9x the minimum monthly wage. students also receive uniforms, textbooks, meals and transportation for the entire school year. in 2017, both schools were among the top-ranked institutions in the national high school exam (enem, in portuguese), and juarez wanderley was ranked 8 th in the state of s√£o paulo. in addition, more than 80% of their alumni were admitted to public universities across brazil. con- sidering those admitted in private universities with full scholarships, the rate of graduates who attend a college-level institution exceeds 90%. some of these students receive financial sup- port from the scholarship fund, an initiative supported by contributions from businesses and individuals as well as from former grantees, whorefund the program after entering the job market. the embraer institute also provides finan- cial support to nonprofit social organizations, through the social partnership program (pps, in portuguese). the initiative is aimed at sup- porting projects aligned with the united nations sustainable development goals (sdgs). in 2017, it supported 12 organizations by investing up to r$40,000 per project. the entity also operates the embraer historic center, whose purpose is to preserve and pro- mote the history of the brazilian aviation industry. it currently has exhibition spaces at embraer units, organizes virtual exhibits and monthly guided tours to the s√£o jos√© dos campos man- ufacturing plant to community members. some of the highlights of 2017 include the ‚äúde- sign in brazilian aviation‚äù exhibit, which was at- tended by more than 40,000 visitors to the museu da casa brasileira (mcb), in s√£o paulo. the embraer institute also earned the 2017 aberje award, the country‚äôs leading corporate commu- nications award. the institute was recognized by the brazilian association of corporate communi- cations (aberje, in portuguese), in the historical responsibility and business memory category, for its efforts to preserve aeronautical memory over the course of the year. in 2017, the company created the embraer foun- dation, which consolidates all of the company‚äôs social initiatives in the united states. as is the case with the institute in brazil, the foundation establishes social partnerships, engages employ- ees in volunteering programs and promotes an entrepreneurial culture among members of the communities served. learn more at www.centrohistoricoembraer.com.br\n","##Warning: token length larger than the maximum (529). Splitting answer into partially overlapped chunks...\n","social standards gri 401: employment  ‚äì hiring of new employees and turnover the hiring and retaining of people at the company must be based on equity regarding color, gen- der, race, nationality, social position, religion, marital status and physical characteristics, respect- ing the exceptions set forth in the current legislation or the specific requirements of the jobs.total number of employees and turnover by age group, gender and region 2017 country age group men women grand total total % total % total % brazil under 30 108 0.59 35 0.19 143 0.78 between 30 and 50 452 2.45 110 0.60 562 3.05 over 50 239 1.30 25 0.14 264 1.43 total  799 4.33 170 0.92 969 5.26 china under 30 0 0.00 0 0.00 0 0.00 between 30 and 50 6 0.03 3 0.02 9 0.05 over 50 0 0.00 0 0.00 0 0.00 total  6 0.03 3 0.02 9 0.05 france under 30 9 0.05 2 0.01 11 0.06 between 30 and 50 6 0.03 1 0.01 7 0.04 over 50 1 0.01 0 0.00 1 0.01 total  16 0.09 3 0.02 19 0.10 portugal under 30 26 0.14 2 0.01 28 0.15 between 30 and 50 26 0.14 14 0.08 40 0.22 over 50 0 0.00 0 0.00 0 0.00 total  52 0.28 16 0.09 68 0.37 netherlands under 30 1 0.01 2 0.01 3 0.02 between 30 and 50 3 0.02 0 0.00 3 0.02 over 50 1 0.01 0 0.00 1 0.01 total  5 0.03 2 0.01 7 0.04 singapore under 30 0 0.00 1 0.01 1 0.01 between 30 and 50 3 0.02 2 0.01 5 0.03 over 50 2 0.01 0 0.00 2 0.01 total  5 0.03 3 0.02 8 0.04 usa under 30 133 0.72 27 0.15 160 0.87 between 30 and 50 98 0.53 17 0.09 115 0.62 over 50 41 0.22 9 0.05 50 0.27 total  272 1.48 53 0.29 325 1.76 grand total 1,155 6.27 250 1.36 1,405 7.62\n","##Warning: token length larger than the maximum (661). Splitting answer into partially overlapped chunks...\n","|, , , , , direct economic impact, local communities| social investment in brazil is coordinated by the embraer institute for education and research, which for more than 15 years promotes educa- tion-related projects, engagement with civil soci- ety and the historic preservation of the country‚äôs aeronautical industry. the main initiatives include the juarez wan- derley (s√£o jos√© dos campos, s√£o paulo) and casimiro montenegro filho (botucatu, s√£o paulo) schools, which offer free, full-time high school education to students coming from public schools and whose household income is lower than 9x the minimum monthly wage. students also receive uniforms, textbooks, meals and transportation for the entire school year. in 2017, both schools were among the top-ranked institutions in the national high school exam (enem, in portuguese), and juarez wanderley was ranked 8 th in the state of s√£o paulo. in addition, more than 80% of their alumni were admitted to public universities across brazil. con- sidering those admitted in private universities with full scholarships, the rate of graduates who attend a college-level institution exceeds 90%. some of these students receive financial sup- port from the scholarship fund, an initiative supported by contributions from businesses and individuals as well as from former grantees, whorefund the program after entering the job market. the embraer institute also provides finan- cial support to nonprofit social organizations, through the social partnership program (pps, in portuguese). the initiative is aimed at sup- porting projects aligned with the united nations sustainable development goals (sdgs). in 2017, it supported 12 organizations by investing up to r$40,000 per project. the entity also operates the embraer historic center, whose purpose is to preserve and pro- mote the history of the brazilian aviation industry. it currently has exhibition spaces at embraer units, organizes virtual exhibits and monthly guided tours to the s√£o jos√© dos campos man- ufacturing plant to community members. some of the highlights of 2017 include the ‚äúde- sign in brazilian aviation‚äù exhibit, which was at- tended by more than 40,000 visitors to the museu da casa brasileira (mcb), in s√£o paulo. the embraer institute also earned the 2017 aberje award, the country‚äôs leading corporate commu- nications award. the institute was recognized by the brazilian association of corporate communi- cations (aberje, in portuguese), in the historical responsibility and business memory category, for its efforts to preserve aeronautical memory over the course of the year. in 2017, the company created the embraer foun- dation, which consolidates all of the company‚äôs social initiatives in the united states. as is the case with the institute in brazil, the foundation establishes social partnerships, engages employ- ees in volunteering programs and promotes an entrepreneurial culture among members of the communities served. learn more at www.centrohistoricoembraer.com.br\n","##Warning: token length larger than the maximum (527). Splitting answer into partially overlapped chunks...\n","senses and flavors through the brf volunteer program, which is transversal to all the work of the institute, we implemented the senses and flavors (‚äúsen- tidos e sabores‚äù) project in associations of municipalities, organizations and other insti- tutions. the focus of this project is to address the theme of food in a playful way, adapted to different audiences in the municipalities, where we are to promote healthier communi- ties. due to a strategic direction, investments in infrastructure were hardly made in 2018 (about r$ 50k).  gri  projects fund we continue with the local partnerships of the \"project fund\" initiative in 2018, with social organizations, schools and residents' associations, ensuring local relevance to the activities carried out. the social investment committees had the possibility to create and lead projects of social relevance, built with local partners. in 2018, 19 fund projects were carried out, in the total amount of almost r$ 70k. gri  recycling and action (‚äúrecicla√á√éo‚äù) another highlight is the recycling and action project, which since 2013 has maintained a program of environmental education, com- munity mobilization and solid waste man- agement, with the objective of eradicating social and environmental risks in morro dos prazeres, in the santa teresa district of rio de janeiro. this performance is based on a model of behavior change of the residents. waste sent for recycling is sold to recyclers and partnerships, generating resources for the community to reinvest in local projects and improving the living conditions of the place. the methodology was recognized by management model gri  the brf institute is a private association of public interest founded by brf to strategical- ly direct the company's social investments. it is qualified as a civil society organization of public interest (oscip) and acts both through its own resources, donated by brf, and by the orientation of the investment of resources encouraged by state laws. its activities under- go annual financial auditing.the governance of the brf institute is com- posed of an associate assembly, a fiscal council and a board of directors divided between the chief executive officer and the executive board. there is a technical team directed only to the activities of the associa- tion that maintains a constant dialogue with stakeholders and leaderships of the brf itself. its main volunteers are the social investment committees, which actively participate in the design of the action strategies.\n","##Warning: token length larger than the maximum (527). Splitting answer into partially overlapped chunks...\n","senses and flavors through the brf volunteer program, which is transversal to all the work of the institute, we implemented the senses and flavors (‚äúsen- tidos e sabores‚äù) project in associations of municipalities, organizations and other insti- tutions. the focus of this project is to address the theme of food in a playful way, adapted to different audiences in the municipalities, where we are to promote healthier communi- ties. due to a strategic direction, investments in infrastructure were hardly made in 2018 (about r$ 50k).  gri  projects fund we continue with the local partnerships of the \"project fund\" initiative in 2018, with social organizations, schools and residents' associations, ensuring local relevance to the activities carried out. the social investment committees had the possibility to create and lead projects of social relevance, built with local partners. in 2018, 19 fund projects were carried out, in the total amount of almost r$ 70k. gri  recycling and action (‚äúrecicla√á√éo‚äù) another highlight is the recycling and action project, which since 2013 has maintained a program of environmental education, com- munity mobilization and solid waste man- agement, with the objective of eradicating social and environmental risks in morro dos prazeres, in the santa teresa district of rio de janeiro. this performance is based on a model of behavior change of the residents. waste sent for recycling is sold to recyclers and partnerships, generating resources for the community to reinvest in local projects and improving the living conditions of the place. the methodology was recognized by management model gri  the brf institute is a private association of public interest founded by brf to strategical- ly direct the company's social investments. it is qualified as a civil society organization of public interest (oscip) and acts both through its own resources, donated by brf, and by the orientation of the investment of resources encouraged by state laws. its activities under- go annual financial auditing.the governance of the brf institute is com- posed of an associate assembly, a fiscal council and a board of directors divided between the chief executive officer and the executive board. there is a technical team directed only to the activities of the associa- tion that maintains a constant dialogue with stakeholders and leaderships of the brf itself. its main volunteers are the social investment committees, which actively participate in the design of the action strategies.\n","Total: 773, train: 695, validation: 78, ratio: 0.8990944372574385\n","index               int64\n","filename           object\n","text               object\n","gri               float64\n","input_ids          object\n","token_type_ids     object\n","attention_mask     object\n","dtype: object\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a4d449e36964a9982f1160d5e85d457","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/999M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fca4eb3dd00>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fca4eb3dd00>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fca4eb3dd00>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fca64ff9290> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fca64ff9290> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING: AutoGraph could not transform <function wrap at 0x7fca64ff9290> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model (TFBertModel)     TFBaseModelOutputWit 167356416   input_1[0][0]                    \n","                                                                 input_2[0][0]                    \n","                                                                 input_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 3)            2307        tf_bert_model[0][1]              \n","==================================================================================================\n","Total params: 167,358,723\n","Trainable params: 167,358,723\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Training bert-base-multilingual-uncased...\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=uint8>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=bool>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 3) dtype=bool>]\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=uint8>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=bool>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 3) dtype=bool>]\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stdout","text":["11/11 [==============================] - 138s 6s/step - loss: 0.5408 - accuracy: 0.6043\n","Epoch 2/10\n","11/11 [==============================] - 3s 266ms/step - loss: 0.3537 - accuracy: 0.7712\n","Epoch 3/10\n","11/11 [==============================] - 3s 266ms/step - loss: 0.2658 - accuracy: 0.8086\n","Epoch 4/10\n","11/11 [==============================] - 3s 266ms/step - loss: 0.2070 - accuracy: 0.8835\n","Epoch 5/10\n","11/11 [==============================] - 3s 266ms/step - loss: 0.2072 - accuracy: 0.8705\n","Epoch 6/10\n","11/11 [==============================] - 3s 266ms/step - loss: 0.1601 - accuracy: 0.9137\n","Epoch 7/10\n","11/11 [==============================] - 3s 267ms/step - loss: 0.1149 - accuracy: 0.9424\n","Epoch 8/10\n","11/11 [==============================] - 3s 266ms/step - loss: 0.1047 - accuracy: 0.9424\n","Epoch 9/10\n","11/11 [==============================] - 3s 266ms/step - loss: 0.0794 - accuracy: 0.9496\n","Epoch 10/10\n","11/11 [==============================] - 3s 267ms/step - loss: 0.0670 - accuracy: 0.9540\n","index               int64\n","filename           object\n","text               object\n","gri               float64\n","input_ids          object\n","token_type_ids     object\n","attention_mask     object\n","dtype: object\n"]},{"output_type":"stream","name":"stderr","text":["INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int32>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 512) dtype=uint8>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 512) dtype=bool>]\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stdout","text":["=======================================\n","Accuracy:\t\t+84.9315%\n","F1-score:\t\t+81.1794%\n","Precision:\t\t+81.3083%\n","Recall:\t\t\t+81.5657%\n","bert-base-multilingual-uncased-512\t0.8493150684931506\t0.8117944147355912\t[0.5407583713531494, 0.35366320610046387, 0.2657684087753296, 0.20697268843650818, 0.20719319581985474, 0.16005904972553253, 0.11494284123182297, 0.10466306656599045, 0.07935904711484909, 0.06696967780590057]\r\n","\n","bert-base-multilingual-uncased-512\t0.8493150684931506\t0.8117944147355912\t0\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSOSrXPu5InZ","executionInfo":{"status":"ok","timestamp":1632473622722,"user_tz":180,"elapsed":431,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"ee15d731-09bc-4339-98a5-0b92e8d11be6"},"source":["## HW characteristics\n","!cat /proc/cpuinfo\n","!cat /proc/meminfo"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 0\n","cpu cores\t: 20\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 1\n","cpu cores\t: 20\n","apicid\t\t: 2\n","initial apicid\t: 2\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 2\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 2\n","cpu cores\t: 20\n","apicid\t\t: 4\n","initial apicid\t: 4\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 3\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 3\n","cpu cores\t: 20\n","apicid\t\t: 6\n","initial apicid\t: 6\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 4\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 4\n","cpu cores\t: 20\n","apicid\t\t: 8\n","initial apicid\t: 8\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 5\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 5\n","cpu cores\t: 20\n","apicid\t\t: 10\n","initial apicid\t: 10\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 6\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 6\n","cpu cores\t: 20\n","apicid\t\t: 12\n","initial apicid\t: 12\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 7\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 7\n","cpu cores\t: 20\n","apicid\t\t: 14\n","initial apicid\t: 14\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 8\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 8\n","cpu cores\t: 20\n","apicid\t\t: 16\n","initial apicid\t: 16\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 9\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 9\n","cpu cores\t: 20\n","apicid\t\t: 18\n","initial apicid\t: 18\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 10\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 10\n","cpu cores\t: 20\n","apicid\t\t: 20\n","initial apicid\t: 20\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 11\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 11\n","cpu cores\t: 20\n","apicid\t\t: 22\n","initial apicid\t: 22\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 12\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 12\n","cpu cores\t: 20\n","apicid\t\t: 24\n","initial apicid\t: 24\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 13\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 13\n","cpu cores\t: 20\n","apicid\t\t: 26\n","initial apicid\t: 26\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 14\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 14\n","cpu cores\t: 20\n","apicid\t\t: 28\n","initial apicid\t: 28\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 15\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 15\n","cpu cores\t: 20\n","apicid\t\t: 30\n","initial apicid\t: 30\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 16\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 16\n","cpu cores\t: 20\n","apicid\t\t: 32\n","initial apicid\t: 32\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 17\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 17\n","cpu cores\t: 20\n","apicid\t\t: 34\n","initial apicid\t: 34\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 18\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 18\n","cpu cores\t: 20\n","apicid\t\t: 36\n","initial apicid\t: 36\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 19\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 19\n","cpu cores\t: 20\n","apicid\t\t: 38\n","initial apicid\t: 38\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 20\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 0\n","cpu cores\t: 20\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 21\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 1\n","cpu cores\t: 20\n","apicid\t\t: 3\n","initial apicid\t: 3\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 22\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 2\n","cpu cores\t: 20\n","apicid\t\t: 5\n","initial apicid\t: 5\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 23\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 3\n","cpu cores\t: 20\n","apicid\t\t: 7\n","initial apicid\t: 7\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 24\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 4\n","cpu cores\t: 20\n","apicid\t\t: 9\n","initial apicid\t: 9\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 25\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 5\n","cpu cores\t: 20\n","apicid\t\t: 11\n","initial apicid\t: 11\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 26\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 6\n","cpu cores\t: 20\n","apicid\t\t: 13\n","initial apicid\t: 13\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 27\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 7\n","cpu cores\t: 20\n","apicid\t\t: 15\n","initial apicid\t: 15\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 28\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 8\n","cpu cores\t: 20\n","apicid\t\t: 17\n","initial apicid\t: 17\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 29\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 9\n","cpu cores\t: 20\n","apicid\t\t: 19\n","initial apicid\t: 19\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 30\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 10\n","cpu cores\t: 20\n","apicid\t\t: 21\n","initial apicid\t: 21\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 31\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 11\n","cpu cores\t: 20\n","apicid\t\t: 23\n","initial apicid\t: 23\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 32\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 12\n","cpu cores\t: 20\n","apicid\t\t: 25\n","initial apicid\t: 25\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 33\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 13\n","cpu cores\t: 20\n","apicid\t\t: 27\n","initial apicid\t: 27\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 34\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 14\n","cpu cores\t: 20\n","apicid\t\t: 29\n","initial apicid\t: 29\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 35\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 15\n","cpu cores\t: 20\n","apicid\t\t: 31\n","initial apicid\t: 31\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 36\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 16\n","cpu cores\t: 20\n","apicid\t\t: 33\n","initial apicid\t: 33\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 37\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 17\n","cpu cores\t: 20\n","apicid\t\t: 35\n","initial apicid\t: 35\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 38\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 18\n","cpu cores\t: 20\n","apicid\t\t: 37\n","initial apicid\t: 37\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 39\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 40\n","core id\t\t: 19\n","cpu cores\t: 20\n","apicid\t\t: 39\n","initial apicid\t: 39\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","MemTotal:       36961176 kB\n","MemFree:        22826712 kB\n","MemAvailable:   35034144 kB\n","Buffers:          153168 kB\n","Cached:          6561840 kB\n","SwapCached:            0 kB\n","Active:          1519712 kB\n","Inactive:       11724500 kB\n","Active(anon):     854360 kB\n","Inactive(anon):      524 kB\n","Active(file):     665352 kB\n","Inactive(file): 11723976 kB\n","Unevictable:           0 kB\n","Mlocked:               0 kB\n","SwapTotal:             0 kB\n","SwapFree:              0 kB\n","Dirty:            338340 kB\n","Writeback:         68788 kB\n","AnonPages:       6529940 kB\n","Mapped:           540184 kB\n","Shmem:              1160 kB\n","KReclaimable:     316756 kB\n","Slab:             552808 kB\n","SReclaimable:     316756 kB\n","SUnreclaim:       236052 kB\n","KernelStack:       16944 kB\n","PageTables:        22448 kB\n","NFS_Unstable:          0 kB\n","Bounce:                0 kB\n","WritebackTmp:          0 kB\n","CommitLimit:    18480588 kB\n","Committed_AS:   19124404 kB\n","VmallocTotal:   34359738367 kB\n","VmallocUsed:       20320 kB\n","VmallocChunk:          0 kB\n","Percpu:            28000 kB\n","AnonHugePages:    387072 kB\n","ShmemHugePages:        0 kB\n","ShmemPmdMapped:        0 kB\n","FileHugePages:         0 kB\n","FilePmdMapped:         0 kB\n","CmaTotal:              0 kB\n","CmaFree:               0 kB\n","HugePages_Total:       0\n","HugePages_Free:        0\n","HugePages_Rsvd:        0\n","HugePages_Surp:        0\n","Hugepagesize:       2048 kB\n","Hugetlb:               0 kB\n","DirectMap4k:      191296 kB\n","DirectMap2M:     8194048 kB\n","DirectMap1G:    31457280 kB\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8TcIIHtG7UTS","executionInfo":{"status":"ok","timestamp":1632473622722,"user_tz":180,"elapsed":55,"user":{"displayName":"Nick Ruberg","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14972801878607051734"}},"outputId":"ecbe60be-4ecf-4d21-ab6e-1e0677915902"},"source":["! nvidia-smi"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"]}]}]}